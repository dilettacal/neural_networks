{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - Vortrag\n",
    "### HTW Berlin - Angewandte Informatik\n",
    "### Modul \"Ausgewählte Kapitel sozialer Webtechnologien\" (aka Neuronale Netze)\n",
    "\n",
    "#### Diletta Calussi - s0559842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhalte\n",
    "\n",
    "1. Das Framework PyTorch\n",
    "2. PyTorch Fundamentals: Tensors und Gradienten\n",
    "3. Netze in PyTorch definieren: Das Modul `torch.nn`\n",
    "4. MNIST-Classifier in PyTorch\n",
    "5. CNN in PyTorch am Beispiel von XX\n",
    "6. Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Das Framework PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eine ML Open-Source-Bibliothek für python\n",
    "- Basiert auf der in **Lua** geschriebenen Bibliothek **Torch**\n",
    "- Vom Facebook-Forschungsteam für K.I. entwickelt \n",
    "- Erscheinungsjahr: 2016\n",
    "- Unterstützt GPU sowie CPU \n",
    "- High Level \n",
    "\n",
    "\n",
    "### Funktionen\n",
    "* Autograd-System zur Berechnung der Ableitungen bezuüglich einer trainierbaren Variablen\n",
    "* Dynamische Graph-Berechnung \n",
    "    - Anzahl von Neuronen kann sich zur Laufzeit verändern\n",
    "    - If und else-Verzweigungen nach Zweck einstellbar\n",
    "* NumPy Bridge\n",
    "\n",
    "Eine Anleitung für die Installation ist auf der Webseite von [PyTorch](https://pytorch.org/) verfügbar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 0.4.0\n",
      "CUDA is active: True\n",
      "CUDA version: 8.0\n"
     ]
    }
   ],
   "source": [
    "#Installation check\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA is active:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch Fundamentals\n",
    "\n",
    "### 2.1 Tensoren\n",
    "\n",
    "Ein `torch.Tensor` ist eine mehrdimensionale Matrix, die Elemente von einem bestimmten Datentyp enthält. Ein detaillierter Überblick der unterstützten Datentype ist auf der [Webseite von PyTorch](https://pytorch.org/docs/stable/tensors.html) verfügbar.  \n",
    "\n",
    "PyTorch unterstützt sowohl GPU- als auch CPU-Tensoren. Tensoren verfügen über folgende Attribute:\n",
    "- `dtype`, leifert Datentyp\n",
    "- `device`, das Gerät (CPU oder GPU), wo das Tensorobjekt gespeichert ist oder wird\n",
    "- `layout`, Speicherlayout von einem Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1114, -0.7801,  1.0160],\n",
       "        [ 0.7871,  1.0868, -0.0281],\n",
       "        [ 0.3378,  1.0709,  1.1754],\n",
       "        [-1.5334, -1.1289,  0.1204],\n",
       "        [ 0.1722,  0.0489,  0.9199]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor erzeugen\n",
    "x = torch.randn(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1003, -1.0636],\n",
       "         [-1.4326, -0.1731],\n",
       "         [-0.1325,  1.3072]],\n",
       "\n",
       "        [[-0.0246, -1.0492],\n",
       "         [-0.5402,  1.7467],\n",
       "         [-0.4262,  0.0971]],\n",
       "\n",
       "        [[-0.4189,  3.9772],\n",
       "         [ 0.2635,  2.3321],\n",
       "         [-1.6450, -0.1602]],\n",
       "\n",
       "        [[-0.3269,  0.8263],\n",
       "         [ 0.7079, -1.6444],\n",
       "         [ 0.4836, -0.1163]],\n",
       "\n",
       "        [[ 0.4128,  1.2000],\n",
       "         [ 0.0486,  1.0876],\n",
       "         [ 1.1299,  0.0518]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(1,10,(2,3))\n",
    "b = torch.randint(1,10,(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise-Operationen:\n",
      "Addition:  tensor([[  4.,  11.,   9.],\n",
      "        [  9.,  15.,  13.]]) \n",
      "oder: tensor([[  4.,  11.,   9.],\n",
      "        [  9.,  15.,  13.]])\n",
      "************************************************************\n",
      "Subtraktion:  tensor([[ 2., -1.,  3.],\n",
      "        [ 5., -3., -1.]]) \n",
      "oder: tensor([[ 2., -1.,  3.],\n",
      "        [ 5., -3., -1.]])\n",
      "************************************************************\n",
      "Multiplikation:  tensor([[  3.,  30.,  18.],\n",
      "        [ 14.,  54.,  42.]]) \n",
      "oder: tensor([[  3.,  30.,  18.],\n",
      "        [ 14.,  54.,  42.]])\n",
      "************************************************************\n",
      "Division:  tensor([[ 3.0000,  0.8333,  2.0000],\n",
      "        [ 3.5000,  0.6667,  0.8571]]) \n",
      "oder: tensor([[ 3.0000,  0.8333,  2.0000],\n",
      "        [ 3.5000,  0.6667,  0.8571]])\n"
     ]
    }
   ],
   "source": [
    "#Elementwise Operationen\n",
    "print(\"Elementwise-Operationen:\")\n",
    "print(\"Addition: \", torch.add(a,b), \"\\noder:\", a+b)\n",
    "print(\"*\"*60)\n",
    "print(\"Subtraktion: \", torch.sub(a,b), \"\\noder:\", a-b)\n",
    "print(\"*\"*60)\n",
    "print(\"Multiplikation: \", torch.mul(a,b), \"\\noder:\", a*b)\n",
    "print(\"*\"*60)\n",
    "print(\"Division: \", torch.div(a,b), \"\\noder:\", a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für eine Matrizenmultiplikation muss der Tensor resized werden.\n",
    "Dafür sind in PyTorch die Funktionen:\n",
    "- [`reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), \n",
    "- [`resize_()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_) und \n",
    "- [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 72.,  70.],\n",
       "        [ 79.,  96.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "#Reshaping mit reshape\n",
    "resh_b = b.reshape(3,2)\n",
    "print(resh_b.shape)\n",
    "torch.mm(a,resh_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 72.,  70.],\n",
       "        [ 79.,  96.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping mit resize\n",
    "res_b = b.resize(3,2)\n",
    "print(res_b.shape)\n",
    "torch.mm(a,res_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 72.,  70.],\n",
       "        [ 79.,  96.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping mit view\n",
    "b_view = b.view(3,2)\n",
    "torch.mm(a,b_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64\n",
      "<class 'torch.Tensor'> torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2,3))\n",
    "y = torch.zeros(2,3)\n",
    "\n",
    "print(type(x), x.dtype)\n",
    "print(type(y), y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float64\n"
     ]
    }
   ],
   "source": [
    "#Automatisches Casting numpy zu torch\n",
    "z = x + y\n",
    "print(type(z), z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor Umwandlung: \n",
      " tensor([[ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.]], dtype=torch.float64)\n",
      "Nach Umwandlung:\n",
      " tensor([[ 4.,  4.,  4.],\n",
      "        [ 4.,  4.,  4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vor Umwandlung: \\n\", z)\n",
    "#Umwandlung zu numpy\n",
    "#Die zwei Objekte teilen den Speicherraum!\n",
    "\n",
    "#Umwandlung nach numpy\n",
    "xx = z.numpy()\n",
    "#Veräderung des Wertes von z (!)\n",
    "xx += 1.0\n",
    "\n",
    "print(\"Nach Umwandlung:\\n\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 8 4]\n",
      " [4 3 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.33333333, 5.33333333])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis vs dim\n",
    "\n",
    "x = np.random.randint(1, 10,(2,3))\n",
    "print(x)\n",
    "x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  7.,  4.],\n",
      "        [ 3.,  9.,  6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 5.6667,  6.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randint(1,10,(2,3))\n",
    "print(y)\n",
    "y.mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Autograd: Gradienten in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Package `torch.autograd` bietet die Möglichkeit zur automatischen Berechnung der Ableitung bezüglich einer Variablen, die zu einem Computation Graphen gehört.\n",
    "\n",
    "Um die Funktionalität zu nutzen, muss das Flag `requires_grad` bei Tensordeklaration auf `True` gesetzt werden.\n",
    "\n",
    "Beispiel aus der Übung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Modules\n",
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: computational_graph Pages: 1 -->\r\n",
       "<svg width=\"522pt\" height=\"165pt\"\r\n",
       " viewBox=\"0.00 0.00 522.09 164.70\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 160.698)\">\r\n",
       "<title>computational_graph</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-160.698 518.088,-160.698 518.088,4 -4,4\"/>\r\n",
       "<!-- a -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>a</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"94\" cy=\"-138.698\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-134.998\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- + -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>+</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170\" cy=\"-117.698\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-113.998\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\r\n",
       "</g>\r\n",
       "<!-- a&#45;&gt;+ -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>a&#45;&gt;+</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111.423,-134.037C120.556,-131.445 132.143,-128.157 142.523,-125.211\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143.702,-128.515 152.367,-122.418 141.791,-121.781 143.702,-128.515\"/>\r\n",
       "</g>\r\n",
       "<!-- b -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>b</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-84.6978\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-80.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- ln -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>ln</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"94\" cy=\"-84.6978\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-80.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ln</text>\r\n",
       "</g>\r\n",
       "<!-- b&#45;&gt;ln -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>b&#45;&gt;ln</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.1631,-84.6978C44.9425,-84.6978 55.8374,-84.6978 65.7325,-84.6978\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.93,-88.1979 75.93,-84.6978 65.93,-81.1979 65.93,-88.1979\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-88.4978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> </text>\r\n",
       "</g>\r\n",
       "<!-- c -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>c</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170\" cy=\"-63.6978\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-59.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">c</text>\r\n",
       "</g>\r\n",
       "<!-- *  -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>* </title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"252.698\" cy=\"-85.6978\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"252.698\" y=\"-81.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">* </text>\r\n",
       "</g>\r\n",
       "<!-- c&#45;&gt;*  -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>c&#45;&gt;* </title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.721,-68.2562C198.541,-71.206 212.861,-75.11 225.21,-78.4765\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.43,-81.8917 234.999,-81.1452 226.271,-75.1382 224.43,-81.8917\"/>\r\n",
       "</g>\r\n",
       "<!-- +&#45;&gt;*  -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>+&#45;&gt;* </title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.943,-111.376C198.217,-106.905 213.562,-100.82 226.485,-95.6956\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.782,-98.9466 235.788,-92.0068 225.202,-92.4395 227.782,-98.9466\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-106.498\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> </text>\r\n",
       "</g>\r\n",
       "<!-- ln&#45;&gt;+ -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>ln&#45;&gt;+</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.693,-91.6963C120.406,-96.0277 133.091,-101.684 144.147,-106.615\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.771,-109.833 153.329,-110.709 145.622,-103.44 142.771,-109.833\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-104.498\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> </text>\r\n",
       "</g>\r\n",
       "<!-- * -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>*</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"332.396\" cy=\"-45.6978\" rx=\"18\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"332.396\" y=\"-41.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\r\n",
       "</g>\r\n",
       "<!-- * &#45;&gt;* -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>* &#45;&gt;*</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269.048,-77.7951C279.903,-72.207 294.678,-64.6006 307.12,-58.1951\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.788,-61.2732 316.077,-53.5841 305.584,-55.0495 308.788,-61.2732\"/>\r\n",
       "</g>\r\n",
       "<!-- 1/x -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>1/x</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"409.494\" cy=\"-45.6978\" rx=\"22.1965\" ry=\"22.1965\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"409.494\" y=\"-41.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1/x</text>\r\n",
       "</g>\r\n",
       "<!-- *&#45;&gt;1/x -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>*&#45;&gt;1/x</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.437,-45.6978C358.36,-45.6978 368.041,-45.6978 377.209,-45.6978\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.221,-49.1979 387.221,-45.6978 377.221,-42.1979 377.221,-49.1979\"/>\r\n",
       "</g>\r\n",
       "<!-- 1/3  -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>1/3 </title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"252.698\" cy=\"-24.6978\" rx=\"24.8972\" ry=\"24.8972\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"252.698\" y=\"-20.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1/3 </text>\r\n",
       "</g>\r\n",
       "<!-- 1/3 &#45;&gt;* -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>1/3 &#45;&gt;*</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.01,-30.9985C285.844,-33.3861 295.961,-36.1205 305.054,-38.5783\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.196,-41.972 314.763,-41.2024 306.023,-35.2144 304.196,-41.972\"/>\r\n",
       "</g>\r\n",
       "<!-- out -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>out</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"491.34\" cy=\"-45.6978\" rx=\"22.9987\" ry=\"22.9987\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"491.34\" y=\"-41.9978\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">out</text>\r\n",
       "</g>\r\n",
       "<!-- 1/x&#45;&gt;out -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>1/x&#45;&gt;out</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M431.891,-45.6978C439.992,-45.6978 449.401,-45.6978 458.272,-45.6978\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"458.327,-49.1979 468.327,-45.6978 458.327,-42.1979 458.327,-49.1979\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1a184bec1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty graph ad set some attributes\n",
    "f = Digraph('computational_graph', filename='graph_clean.gv')\n",
    "f.attr(rankdir='LR')\n",
    "f.attr('node', shape='circle')\n",
    "\n",
    "# create the graph\n",
    "f.node('a')\n",
    "f.node('b')\n",
    "f.node('c')\n",
    "f.edge('a', '+', label='')\n",
    "f.edge('b', 'ln', label=' ')\n",
    "f.edge('ln', '+', label=' ')\n",
    "f.edge('+','* ', label=' ')\n",
    "f.edge('c','* ')\n",
    "f.edge('* ', '*')\n",
    "f.edge('1/3 ', '*')\n",
    "f.edge('*','1/x')\n",
    "f.edge('1/x','out')\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Graphen sind 3 Variablen:\n",
    "- a (2)\n",
    "- b (e)\n",
    "- c (3)\n",
    "Setzt man das Flag von diesen Variablen auf True, dann werden all die Operationen, die diese Variablen betreffen, vom Framework automatisch registriert. \n",
    "\n",
    "Am Ende eines Forward-Schrittes ist es möglich, die Funktion `backward()` aus `torch.autograd` aufzurufen, die den Backward-Pass brechnet. \n",
    "Über das Attribut `grad` kann man den Wert der Ableitung dann schnell lesen. Das Attribut `grad_fn` zeigt die auf der Variablen angewandte Operationsart (Logarithmus, Summe, Multiplikation, usw.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.) tensor(2.7183) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "#Variablen deklaration\n",
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(np.e, requires_grad=True)\n",
    "c = torch.tensor(3., requires_grad=True)\n",
    "dummy = torch.tensor(1)\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None None\n",
      "True True True False\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad, c.grad, d.grad)\n",
    "print(a.requires_grad, b.requires_grad, c.requires_grad, d.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyExerciseFunction(a,b,c):\n",
    "    ln = torch.log(b)\n",
    "    print(ln.grad_fn)\n",
    "    x = a + ln \n",
    "    print(x.grad_fn)\n",
    "    x = c * x\n",
    "    print(x.grad_fn)\n",
    "    x = (1./3.)*x\n",
    "    print(x.grad_fn)\n",
    "    out = 1./x\n",
    "    print(out.grad_fn)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LogBackward object at 0x000001A184CF5BA8>\n",
      "<AddBackward1 object at 0x000001A184CF5240>\n",
      "<MulBackward1 object at 0x000001A184CF5240>\n",
      "<MulBackward0 object at 0x000001A184CF5240>\n",
      "<MulBackward0 object at 0x000001A184CF5240>\n",
      "Ergebnis aus Fowardpass:  tensor(0.3333)\n"
     ]
    }
   ],
   "source": [
    "out =  applyExerciseFunction(a,b,c) #1/3\n",
    "print(\"Ergebnis aus Fowardpass: \", out) #1./3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(retain_graph=True)#retain_graph bei großen Berechnungen nicht verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout/da:  tensor(-0.1111)\n",
      "dout/db:  tensor(1.00000e-02 *\n",
      "       -4.0875)\n",
      "dout/dc:  tensor(-0.1111)\n"
     ]
    }
   ],
   "source": [
    "print(\"dout/da: \", a.grad)\n",
    "print(\"dout/db: \", b.grad)\n",
    "print(\"dout/dc: \", c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "z = dummy + 2\n",
    "print(z.grad_fn)\n",
    "print(dummy.grad)\n",
    "\n",
    "#Aktivierung des Autograd für dummy\n",
    "dummy.r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
