{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warum lieber PyTorch?\n",
    "\n",
    "Tesorflow:\n",
    "- von Google\n",
    "- Unglaublich Low-Level --> Fast alles selber schreiben\n",
    "    - Flexibilität aber vielleicht...\n",
    "    - Code nicht mehr so gut lesbar :-)\n",
    "    \n",
    "- Man nutzt lieber Keras  \n",
    "    - Nicht von Google\n",
    "    - Debugging nicht so geil :/\n",
    "    - Wirklich easy\n",
    "- Static computation Graph!\n",
    "\n",
    "PyTorch:\n",
    "- von Facebook\n",
    "- High Level (eine Art Keras)\n",
    "- sehr jung --> Windows Version lange \"beta\" geblieben\n",
    "- Viel Umstieg nach PyTorch\n",
    "- Dynamic computation graph :-)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static computation Graphs\n",
    "\n",
    "Beispiel: Daten -> Convolution -> Fully Connected\n",
    "\n",
    "Der Graph ist statisch:\n",
    "- Das Bild ist immer genau dasselbe, z.B. 32x32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Computation Graph\n",
    "- Die Anzahl an Neuronen kann sich zur Laufzeit verändern\n",
    "    - If und else Verzweigungen sind bsp. möglich\n",
    "    - Man kann eine Berechnung für die ersten X-Epochen machen, danach sie verändern\n",
    "Daten -> Convolution:\n",
    "    - If something:\n",
    "        - Pooling A\n",
    "    - Else:\n",
    "        - Pooling B\n",
    "-> Fully Connected    \n",
    "    - Der Input-Layer passt sich quasi den Inputs :-)\n",
    "    - Wie kann das genau so schnell sein, wenn Änderungen zur Laufzeit möglich sind? Läuft fast genau so schnell wie TensorFlow :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2789, -0.2773, -0.0543],\n",
       "        [-0.3424,  1.5185, -1.3986],\n",
       "        [-0.6996,  2.1158, -0.3792],\n",
       "        [ 2.5705,  0.6989, -0.7818],\n",
       "        [ 1.1512, -0.1644,  0.2251]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,3) #Matrix 5x3 (5 Zeilen, 3 Spalten)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0781,  1.7730],\n",
       "         [ 0.1685, -0.5971]],\n",
       "\n",
       "        [[-1.1920, -0.6030],\n",
       "         [ 1.1426,  3.2733]],\n",
       "\n",
       "        [[-0.6611, -0.2770],\n",
       "         [-0.5768,  1.3310]],\n",
       "\n",
       "        [[ 0.0602,  2.3778],\n",
       "         [ 1.8561,  0.3390]],\n",
       "\n",
       "        [[-0.7297,  0.2842],\n",
       "         [-0.0853,  0.6249]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matr3 = torch.randn(5,2,2) #5 2x2 Matrixen\n",
    "matr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(1,10,(2,3))\n",
    "b = torch.randint(1,10,(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementenweise Operationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:  tensor([[  9.,   5.,  12.],\n",
      "        [  7.,   4.,   6.]]) \n",
      "oder: tensor([[  9.,   5.,  12.],\n",
      "        [  7.,   4.,   6.]])\n",
      "************************************************************\n",
      "Subtraktion:  tensor([[ 3.,  1., -6.],\n",
      "        [ 5.,  2.,  0.]]) \n",
      "oder: tensor([[ 3.,  1., -6.],\n",
      "        [ 5.,  2.,  0.]])\n",
      "************************************************************\n",
      "Multiplikation:  tensor([[ 18.,   6.,  27.],\n",
      "        [  6.,   3.,   9.]]) \n",
      "oder: tensor([[ 18.,   6.,  27.],\n",
      "        [  6.,   3.,   9.]])\n",
      "************************************************************\n",
      "Division:  tensor([[ 2.0000,  1.5000,  0.3333],\n",
      "        [ 6.0000,  3.0000,  1.0000]]) \n",
      "oder: tensor([[ 2.0000,  1.5000,  0.3333],\n",
      "        [ 6.0000,  3.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Addition: \", torch.add(a,b), \"\\noder:\", a+b)\n",
    "print(\"*\"*60)\n",
    "print(\"Subtraktion: \", torch.sub(a,b), \"\\noder:\", a-b)\n",
    "print(\"*\"*60)\n",
    "print(\"Multiplikation: \", torch.mul(a,b), \"\\noder:\", a*b)\n",
    "print(\"*\"*60)\n",
    "print(\"Division: \", torch.div(a,b), \"\\noder:\", a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizenmultiplikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA: Berechnungen auf der Grafikkarte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0356,  3.0388, -1.1823,  ...,  1.0606,  1.0627, -0.2655],\n",
       "        [ 1.6800, -0.2064, -0.2593,  ...,  1.9300, -0.8253,  0.1486],\n",
       "        [-0.8029,  1.2764,  2.2142,  ...,  2.4638,  0.6943,  0.0832],\n",
       "        ...,\n",
       "        [ 1.8547, -0.6906, -1.1779,  ..., -1.1348,  3.3192, -0.1652],\n",
       "        [-2.8268, -1.0857,  3.2563,  ...,  1.2146,  0.5481, -1.6993],\n",
       "        [ 1.1480, -0.0482, -0.7900,  ..., -1.7810,  0.8314,  0.5277]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((60000,784))\n",
    "y = torch.randn((60000,784))\n",
    "#Tensors nach CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available\")\n",
    "    x = x.cuda()#\n",
    "    y = y.cuda()\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenes Neuronales Netzwerk in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F #FUnktionen\n",
    "from torch.autograd import Variable #Variablen - kann man backpropagieren\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasse vom Neuronalen Netz erzeugen\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        #Konstruktor aus Superklasse\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        #Layer definieren\n",
    "        self.lin1 = nn.Linear(10,11)\n",
    "        self.lin2 = nn.Linear(11,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Berechnet bis zum Output \"\"\"\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #Letzter Schritt ohne Aktivierungsfunktion\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        \"\"\" \n",
    "        Ausgabe von den Berechnungen aus nn.Module \n",
    "        x ist eine Variable fuer einen Tensor, Tensor ist drinnen\n",
    "        \"\"\" \n",
    "        print(x.size())\n",
    "        print(x.size()[1:])\n",
    "        size = x.size()[1:] #ausser Batch-Dimension\n",
    "        num = 1\n",
    "        for i in size:\n",
    "            num *=i \n",
    "        return num    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestehendes Netz wird geladen\n"
     ]
    }
   ],
   "source": [
    "net = Network()\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "if os.path.isfile(\"net.pt\"):\n",
    "    print(\"Bestehendes Netz wird geladen\")\n",
    "    net = torch.load(\"net.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Netz lernt\n",
    "\n",
    "1. Criterion für Berechnung des Fehlers\n",
    "2. Optimizer für das Lernen\n",
    "\n",
    "Speichern mit `torch.save()`, Laden mit `torch.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0,1,1,0,1,0,0,0,0,0] #\n",
    "target = Variable(torch.Tensor([label for _ in range(10)])) #10x5 targets\n",
    "if torch.cuda.is_available():\n",
    "        target = target.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler:  1.3628334910782171e-14\n",
      "Fehler:  1.3578027929978843e-14\n",
      "Fehler:  1.23345776341789e-14\n",
      "Fehler:  1.1979306605112029e-14\n",
      "Fehler:  1.162542301601276e-14\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    # Baut aus einem Tensor eine Variable, Tensoren sind die Inhalte davon\n",
    "    x = [1,0,0,1,0,1,1,1,1,1] #\n",
    "    input = Variable(torch.Tensor([x for _ in range(10)])) #10x5 targets\n",
    "    if torch.cuda.is_available():\n",
    "        input = input.cuda()\n",
    "    out = net(input)\n",
    "    #print(out) #10x5\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(out, target)\n",
    "    if i % 10 == 0:\n",
    "        print(\"Fehler: \", loss.item())\n",
    "    #print(\"Fehler in der 1.Stufe: \", loss.grad_fn.next_functions[0][0])\n",
    "    net.zero_grad() #Veraenderung auf null setzen\n",
    "    loss.backward() #Backpropagation des Loss\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.10)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,\"net.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST mit PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daten herunterladen und bereitstellen\n",
    "\n",
    "loader = torch.utils.data.DataLoader(datasets.MNIST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
