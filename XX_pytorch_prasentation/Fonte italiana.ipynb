{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://iaml.it/blog/alle-prese-con-pytorch-parte-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vs. NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64\n",
      "<class 'torch.Tensor'> torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2,3))\n",
    "y = torch.zeros(2,3)\n",
    "\n",
    "print(type(x), x.dtype)\n",
    "print(type(y), y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float64\n"
     ]
    }
   ],
   "source": [
    "#Automatisches Casting numpy zu torch\n",
    "z = x + y\n",
    "print(type(z), z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor Umwandlung:  tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "Nach Umwandlung: tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vor Umwandlung: \", z)\n",
    "#Umwandlung zu numpy\n",
    "#Die zwei Objekte teilen den Speicherraum!\n",
    "\n",
    "#Umwandlung nach numpy\n",
    "xx = z.numpy()\n",
    "#Veräderung des Wertes von xx (!)\n",
    "xx += 1.0\n",
    "\n",
    "print(\"Nach Umwandlung:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   2.],\n",
       "        [ 12.,   4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Broadcasting für beide\n",
    "torch.Tensor([3, 2]) * torch.Tensor([[0, 1], [4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.],\n",
       "        [ 7.,  4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([3, 2]) + torch.Tensor([[0, 1], [4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 7]\n",
      " [3 1 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4. , 3.5, 6.5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unterschied: Dimensionen axis vs dim\n",
    "x = np.random.randint(1, 10,(2,3))\n",
    "print(x)\n",
    "x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  2.,  7.],\n",
      "        [ 5.,  6.,  2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5000,  4.0000,  4.5000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(torch.randint(1,10,(2,3)))\n",
    "print(y)\n",
    "y.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Automatische Berechnung des Gradienten\n",
    "\n",
    "#Vor der Version 0.4.0 war eine Variable notwendig. Eine Variable in Torch ist eine \n",
    "#Art Wrapper um einen Tensor. Alle Änderungen an der Variablen werden in Torch innerhalb\n",
    "#eines Graphen gespeichert\n",
    "\n",
    "#Siehe gif\n",
    "\n",
    "#In jedem Moment ist es möglich, den Gradienten von einer Funktion bzgl. eines Tensors\n",
    "#Die notwendigen Informationen werden über den Graphen \n",
    "from torch.autograd import Variable\n",
    "v = Variable(torch.ones(1, 2), requires_grad=True) #Das Flag sagt, dass der Gradient bzgl. v berechenbar ist\n",
    "\n",
    "v_new = torch.ones((1,2), requires_grad=True) #Geht auch jetzt\n",
    "\n",
    "print(v.data) #Unterliegender Tensor\n",
    "print(v.grad) #Nicht initialisierter Gradient. Wird beim Backprop belegt\n",
    "print(v.grad_fn) #So hält PyTorch den \"Überblick\" über den Graphe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "<SumBackward0 object at 0x000001EA03790B70>\n"
     ]
    }
   ],
   "source": [
    "v_fn = torch.sum(v ** 2)\n",
    "print(v_fn.data)    # 2 [torch.FloatTensor of size 1]\n",
    "print(v_fn.grad_fn) # <SumBackward0 object at 0x000001EA03790B70>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.,  2.]]),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graphen sind in PyTorch dynamisch und das Ergebnis der Operationen ist sofort verfügbar\n",
    "# Nicht wie in anderen Bibliotheken \n",
    "\n",
    "#Ausserdem v_fn.grad_fn ist jetzt belegt mit einem Objekt, das die Operation darstellt, die die Variable im Graphen erzeugt hat\n",
    "\n",
    "torch.autograd.grad(v_fn,v)#d(v_fn/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oder\n",
    "v1 = Variable(torch.Tensor([1, 2]), requires_grad=True)\n",
    "v2 = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "v_fn = torch.sum(v1 * v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_fn.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  3.])\n"
     ]
    }
   ],
   "source": [
    "print(v1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.])\n"
     ]
    }
   ],
   "source": [
    "print(v2.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
