{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://iaml.it/blog/alle-prese-con-pytorch-parte-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vs. NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64\n",
      "<class 'torch.Tensor'> torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2,3))\n",
    "y = torch.zeros(2,3)\n",
    "\n",
    "print(type(x), x.dtype)\n",
    "print(type(y), y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float64\n"
     ]
    }
   ],
   "source": [
    "#Automatisches Casting numpy zu torch\n",
    "z = x + y\n",
    "print(type(z), z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor Umwandlung:  tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "Nach Umwandlung: tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vor Umwandlung: \", z)\n",
    "#Umwandlung zu numpy\n",
    "#Die zwei Objekte teilen den Speicherraum!\n",
    "\n",
    "#Umwandlung nach numpy\n",
    "xx = z.numpy()\n",
    "#Veräderung des Wertes von xx (!)\n",
    "xx += 1.0\n",
    "\n",
    "print(\"Nach Umwandlung:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   2.],\n",
       "        [ 12.,   4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Broadcasting für beide\n",
    "torch.Tensor([3, 2]) * torch.Tensor([[0, 1], [4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.],\n",
       "        [ 7.,  4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([3, 2]) + torch.Tensor([[0, 1], [4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 5 9]\n",
      " [2 9 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.5, 7. , 8.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unterschied: Dimensionen axis vs dim\n",
    "x = np.random.randint(1, 10,(2,3))\n",
    "print(x)\n",
    "x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  7.,  4.],\n",
      "        [ 6.,  4.,  3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0000,  5.5000,  3.5000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(torch.randint(1,10,(2,3)))\n",
    "print(y)\n",
    "y.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Automatische Berechnung des Gradienten\n",
    "\n",
    "#Vor der Version 0.4.0 war eine Variable notwendig. Eine Variable in Torch ist eine \n",
    "#Art Wrapper um einen Tensor. Alle Änderungen an der Variablen werden in Torch innerhalb\n",
    "#eines Graphen gespeichert\n",
    "\n",
    "#Siehe gif\n",
    "\n",
    "#In jedem Moment ist es möglich, den Gradienten von einer Funktion bzgl. eines Tensors\n",
    "#Die notwendigen Informationen werden über den Graphen \n",
    "from torch.autograd import Variable\n",
    "v = Variable(torch.ones(1, 2), requires_grad=True) #Das Flag sagt, dass der Gradient bzgl. v berechenbar ist\n",
    "\n",
    "v_new = torch.ones((1,2), requires_grad=True) #Geht auch jetzt\n",
    "\n",
    "print(v.data) #Unterliegender Tensor\n",
    "print(v.grad) #Nicht initialisierter Gradient. Wird beim Backprop belegt\n",
    "print(v.grad_fn) #So hält PyTorch den \"Überblick\" über den Graphe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "<SumBackward0 object at 0x0000018E2A216128>\n"
     ]
    }
   ],
   "source": [
    "v_fn = torch.sum(v ** 2)\n",
    "print(v_fn.data)    # 2 [torch.FloatTensor of size 1]\n",
    "print(v_fn.grad_fn) # <SumBackward0 object at 0x000001EA03790B70>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.,  2.]]),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graphen sind in PyTorch dynamisch und das Ergebnis der Operationen ist sofort verfügbar\n",
    "# Nicht wie in anderen Bibliotheken \n",
    "\n",
    "#Ausserdem v_fn.grad_fn ist jetzt belegt mit einem Objekt, das die Operation darstellt, die die Variable im Graphen erzeugt hat\n",
    "\n",
    "torch.autograd.grad(v_fn,v)#d(v_fn/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oder\n",
    "v1 = Variable(torch.Tensor([1, 2]), requires_grad=True)\n",
    "v2 = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "v_fn = torch.sum(v1 * v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_fn.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  3.])\n"
     ]
    }
   ],
   "source": [
    "print(v1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.])\n"
     ]
    }
   ],
   "source": [
    "print(v2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reti neurali con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Dataset\n",
    "data = datasets.load_iris()\n",
    "Xtrain, Xtest, ytrain, ytest = model_selection.train_test_split(data['data'], data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.from_numpy(Xtrain).float()\n",
    "Xtest = torch.from_numpy(Xtest).float()\n",
    "ytrain = torch.from_numpy(ytrain)\n",
    "ytest = torch.from_numpy(ytest)\n",
    "\n",
    "train_data = data.TensorDataset(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 4.9000,  3.6000,  1.4000,  0.1000], dtype=torch.float32), tensor(0, dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batching\n",
    "\n",
    "Ein PyTorch-Loader ermöglicht die Extraktion von Mini-Batches mit fester Dimension (32) aus dem Datensatz. Man kann außerdem die Daten \"mischen\", nachdem während der Training-Phase der ganze Datensatz durchgelaufen wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = \n",
    "data.DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuronales Netz erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modul torch.nn\n",
    "\n",
    "#1. Modell initialisieren\n",
    "in_features = 4 #Size of each input sample\n",
    "out_features = 3 #size of each output sample\n",
    "linear_modell = nn.Linear(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelle von PyTorch kann man direkt aufrufen, als wären sie Funktionen. Jedes Modell kann 3 Parameter bekommen:\n",
    "- in_features, die Dimension von jedem Train sample\n",
    "- out_features, die Dimension von jedem Out sample\n",
    "- bias Flag, das automatisch als True gesetzt wird\n",
    "\n",
    "Falls nicht anderes angegeben, werden Gewichte und Bias-Vektor automatisch initialisiert. Um sie zu untersuchen:\n",
    "- `modell.weights`\n",
    "- `modell.bias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3781,  0.4100, -0.1801,  0.1460],\n",
      "        [ 0.1437,  0.2224,  0.0421,  0.2907],\n",
      "        [-0.3957,  0.4232, -0.2028, -0.3855]])\n",
      "Parameter containing:\n",
      "tensor([ 0.1286,  0.0197,  0.1669])\n"
     ]
    }
   ],
   "source": [
    "print(linear_modell.weight)\n",
    "print(linear_modell.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6437,  2.4616, -2.8560]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Vorhersage \n",
    "linear_modell(Xtrain[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell definieren mit `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Codice per l'inizializzazione\n",
    "        #In dieser Phase müssen die Dimensionen explizit festgestellt werden\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden = nn.Linear(4, 10) #nur 1 Layer\n",
    "        self.relu = nn.ReLU() #ReLU als Aktivierungsfunktion\n",
    "        self.drop = nn.Dropout(0.2) #Dropout\n",
    "        self.out = nn.Linear(10, 3) #Output layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Codice per la forward pass\n",
    "        x = self.relu(self.hidden(x))\n",
    "        return self.out(self.drop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3488, -1.1158, -0.5085]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CustomModel()\n",
    "net(Variable(Xtrain[0:1].double()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (hidden): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (drop): Dropout(p=0.2)\n",
      "  (out): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "\"\"\"\n",
    "Das Modell enthält vier Variablen (Parameter):\n",
    "- 2 Matrizen für das Modul \"hidden\"\n",
    "- 2 Matrizen für das Modul out\n",
    "- Aktivierungs-Funktion und Dropout verfügen über keine veränderbaren Elemente\n",
    "\"\"\"\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0572, -0.4209,  0.1912, -0.3214],\n",
       "        [-0.4439, -0.3029, -0.4806,  0.4752],\n",
       "        [-0.1467,  0.2918,  0.2821, -0.1402],\n",
       "        [ 0.1045, -0.4957, -0.4089,  0.3862],\n",
       "        [-0.2103,  0.2899,  0.4866,  0.1740],\n",
       "        [-0.1592, -0.2207,  0.2786,  0.2478],\n",
       "        [-0.2542, -0.1431, -0.4053, -0.1773],\n",
       "        [ 0.4671,  0.4594,  0.0713,  0.4903],\n",
       "        [-0.3344, -0.2171,  0.2291, -0.0523],\n",
       "        [-0.3880,  0.0780,  0.2479, -0.0812]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz im hidden\n",
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4804,  0.0482, -0.4793,  0.2383, -0.4524, -0.2515,  0.0143,\n",
       "        -0.3773, -0.4165,  0.4315])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hidden bias \n",
    "params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0983,  0.0238, -0.3012,  0.2116, -0.1005, -0.2183,  0.0974,\n",
       "         -0.0709, -0.2014, -0.1451],\n",
       "        [ 0.1445,  0.0929, -0.0502, -0.0109,  0.2117, -0.0500,  0.1771,\n",
       "         -0.1964, -0.2392,  0.1495],\n",
       "        [ 0.1761,  0.2689, -0.1101, -0.2165,  0.0362, -0.1333, -0.2767,\n",
       "         -0.1224, -0.2394, -0.2648]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Out Matriz\n",
    "params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1008, -0.2578,  0.0803])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Out bias \n",
    "params[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "print(sum([torch.numel(p) for p in params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('out.bias', Parameter containing:\n",
      "tensor([ 0.1008, -0.2578,  0.0803]))\n"
     ]
    }
   ],
   "source": [
    "named_params = [p for p in net.named_parameters()]\n",
    "print(named_params[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternativen für die Definition von Modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F # Funktion-Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(x):\n",
    "    return F.softmax(lin(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Einige Module aus nn verfügen über den Flag inplace\n",
    "\n",
    "relu_inplace = nn.ReLU(inplace=True) #Erzeugt keine vorläufige Daten, überschreibt Speicherplatz aus vorigen Variablen\n",
    "#Nicht empfohlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_sequential = nn.Sequential(\n",
    "        nn.Linear(4, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(10, 3)\n",
    ")\n",
    "#Genau so wie CustomModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellparameter initialisieren "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineare Transformation:\n",
    "- Gewichte sollen normal verteilt sein\n",
    "- Bias soll eine Kostante sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net == CustomModel\n",
    "#torch.nn.init.normal_(net.hidden.weight.data)\n",
    "#torch.nn.init.constant_(net.hidden.bias.data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7305,  0.3964, -0.2573, -0.0011],\n",
      "        [-0.4309,  0.9170, -1.1736, -0.9769],\n",
      "        [-0.2152, -0.9050,  1.0083, -0.0172],\n",
      "        [-2.2362,  0.1824,  0.5407,  1.0028],\n",
      "        [ 0.0625, -1.3347,  0.4600,  0.9234],\n",
      "        [ 0.9169,  0.5341,  0.2630, -0.0013],\n",
      "        [ 0.7701,  0.2374, -0.2747,  1.0766],\n",
      "        [ 0.6155, -0.9617,  0.9946, -0.0223],\n",
      "        [-1.4404, -0.1611, -0.3173,  0.0046],\n",
      "        [ 1.2417, -0.2064,  0.5981, -0.6571]])\n",
      "Parameter containing:\n",
      "tensor([ 0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.init.normal_(net.hidden.weight))\n",
    "print(torch.nn.init.constant_(net.hidden.bias, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Falls Modell besonders komplex ist\n",
    "for m in net.modules():\n",
    "    if type(m) in ['Linear']:\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netz optimieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CustomModel()\n",
    "net = net.double()\n",
    "loss = nn.MSELoss() #gut für Klassifizierung\n",
    "opt = torch.optim.Adam(params=net.parameters(), lr=0.01) #Adam konvergiert schnell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = Variable(Xtrain)\n",
    "yt = Variable(ytrain)\n",
    "\n",
    "def train_step(x,y):\n",
    "    torch.DoubleTensor(x.double())\n",
    "    torch.DoubleTensor(y.double())\n",
    "    #torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "    #Training-Modalität\n",
    "    net.train()\n",
    "    \n",
    "    #Vorhersagen berechnen\n",
    "    y_pred = net(x)\n",
    "    \n",
    "    # Calcola funzione costo\n",
    "    loss_epoch = loss(y_pred, y)\n",
    "\n",
    "  # Esegui back-propagation\n",
    "    loss_epoch.backward()\n",
    "\n",
    "  # Aggiorna le variabili\n",
    "    opt.step()\n",
    "\n",
    "  # Resetta il gradiente\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    correct = (y_pred.max(dim=1)[1] == y_true)\n",
    "    return torch.mean(correct.float()).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-16706aa2ad71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-214-46e5f96b55cc>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Vorhersagen berechnen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Calcola funzione costo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-178-84b1460b332c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Codice per la forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    990\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    net.train()\n",
    "    for Xb, yb in train_data_loader:\n",
    "        train_step(Variable(Xb), Variable(yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "fmnist = datasets.FashionMNIST('fmnist', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_test = datasets.FashionMNIST('fmnist', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x18E312A55F8>, tensor(9))\n"
     ]
    }
   ],
   "source": [
    "print(len(fmnist))\n",
    "# Ritorna: 60000\n",
    "print(fmnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "fmnist = datasets.FashionMNIST('fmnist', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18e35c01e80>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creiamo un loader per mini-batch di sedici immagini\n",
    "from torch.utils import data\n",
    "data_loader = data.DataLoader(fmnist, batch_size=16)\n",
    "\n",
    "# Prendiamo il primo mini-batch\n",
    "xb, yb = next(iter(data_loader))\n",
    "\n",
    "# Lo stampiamo su schermo\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "out = utils.make_grid(xb)\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dobbia trasformazione\n",
    "tr = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=75),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "fmnist = datasets.FashionMNIST('fmnist', train=True, transform=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x < 0.5).float())\n",
    "])\n",
    "fmnist = datasets.FashionMNIST('fmnist', transform=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola media e variazione standard\n",
    "import numpy as np\n",
    "im_mean = np.mean(fmnist.train_data.numpy())\n",
    "im_std = np.std(fmnist.train_data.numpy())\n",
    "\n",
    "# Applica la normalizzazione\n",
    "tr = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((im_mean / 255.0,), (im_std / 255.0,))\n",
    "])\n",
    "fmnist = datasets.FashionMNIST('fmnist', train=True, transform=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
