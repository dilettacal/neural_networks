{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - Vortrag\n",
    "### HTW Berlin - Angewandte Informatik (B. Sc.)\n",
    "#### Modul \"Ausgewählte Kapitel sozialer Webtechnologien\" (aka Neuronale Netze)\n",
    "\n",
    "##### Diletta Calussi - s0559842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhalte\n",
    "\n",
    "1. Das Framework PyTorch\n",
    "2. PyTorch Fundamentals (Warm-up)\n",
    "3. Neuronale Netze in PyTorch\n",
    "4. Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Das Framework [PyTorch](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eine ML Open-Source-Bibliothek für python\n",
    "- Basiert auf der in [**Lua**](https://www.lua.org/) geschriebenen Bibliothek [**Torch**](http://torch.ch/)\n",
    "- Vom Facebook-Forschungsteam für K.I. entwickelt \n",
    "- Erscheinungsjahr: 2016\n",
    "- Unterstützt GPU sowie CPU \n",
    "- High Level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurze Übersicht\n",
    "\n",
    "1. Tensoren\n",
    "2. Dynamische Graphen (Dynamic Computational Graph)\n",
    "3. Autograd-System zur Berechnung der Ableitungen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages für diese Präsentation\n",
    "- torch (CUDA oder GPU)\n",
    "- torchvision\n",
    "- numpy\n",
    "\n",
    "\n",
    "\n",
    "Eine Anleitung für die Installation ist auf der Webseite von [PyTorch](https://pytorch.org/) verfügbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 0.4.1\n",
      "CUDA is active: True\n",
      "CUDA version: 8.0\n"
     ]
    }
   ],
   "source": [
    "#Installation check\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA is active:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch Fundamentals (Warm-up)\n",
    "\n",
    "PyTorch bietet zwei Abstraktionen für Datenstrukturen: Tensoren und Variablen. Tensoren sind so ähnlich wie NumPy-Arrays und können auch auf GPUs übertragen werden. Variablen waren bis zur Version 0.4. als Wrapper um Tensoren notwendig, um bsp. die Berechnung der Gradienten zu ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tensoren\n",
    "\n",
    "Ein `torch.Tensor` ist eine mehrdimensionale Matrix, die Elemente von einem bestimmten Datentyp enthält. Ein detaillierter Überblick der unterstützten Datentype ist auf der [Webseite von PyTorch](https://pytorch.org/docs/stable/tensors.html) verfügbar.  \n",
    "\n",
    "PyTorch unterstützt sowohl GPU- als auch CPU-Tensoren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispiele aus der [PyTorch-Webseite](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0000]])\n",
      "tensor([[0.1622, 0.0688, 0.7916],\n",
      "        [0.5695, 0.0396, 0.9926],\n",
      "        [0.1748, 0.2957, 0.8233],\n",
      "        [0.7330, 0.2710, 0.6552],\n",
      "        [0.7196, 0.0887, 0.1258]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([5.5000, 3.0000])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2490,  0.8078, -0.6586],\n",
      "        [-0.2367,  0.7260, -0.5984],\n",
      "        [-1.2892, -0.5238,  0.6326],\n",
      "        [-1.7466, -0.1070, -1.8256],\n",
      "        [ 0.5493, -0.5402, -0.7741]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "#5x3 matrix, nicht initialisiert\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "#Random-Initialisierung\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "#Matrix filled with zeros mit Typ Long\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "#Tensor aus Daten\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)\n",
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operationen auf Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 8., 4.],\n",
      "        [7., 1., 3.]])\n",
      "\n",
      "tensor([[5., 6., 3.],\n",
      "        [6., 7., 5.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(1,10,(2,3))\n",
    "b = torch.randint(1,10,(2,3))\n",
    "print(a)\n",
    "print()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise-Operationen:\n",
      "Addition: \n",
      " tensor([[ 8., 14.,  7.],\n",
      "        [13.,  8.,  8.]]) \n",
      "oder: tensor([[ 8., 14.,  7.],\n",
      "        [13.,  8.,  8.]])\n",
      "************************************************************\n",
      "Subtraktion:\n",
      " tensor([[-2.,  2.,  1.],\n",
      "        [ 1., -6., -2.]]) \n",
      "oder: tensor([[-2.,  2.,  1.],\n",
      "        [ 1., -6., -2.]])\n",
      "************************************************************\n",
      "Multiplikation:\n",
      " tensor([[15., 48., 12.],\n",
      "        [42.,  7., 15.]]) \n",
      "oder: tensor([[15., 48., 12.],\n",
      "        [42.,  7., 15.]])\n",
      "************************************************************\n",
      "Division:\n",
      " tensor([[0.6000, 1.3333, 1.3333],\n",
      "        [1.1667, 0.1429, 0.6000]]) \n",
      "oder: tensor([[0.6000, 1.3333, 1.3333],\n",
      "        [1.1667, 0.1429, 0.6000]])\n",
      "************************************************************\n",
      "IN-PLACE: \n",
      "tensor([[ 8., 14.,  7.],\n",
      "        [13.,  8.,  8.]])\n",
      "tensor([[ 8., 14.,  7.],\n",
      "        [13.,  8.,  8.]])\n"
     ]
    }
   ],
   "source": [
    "#Elementwise Operationen (mit den Funktionen .add(), .sub(), .mul(), .div())\n",
    "print(\"Elementwise-Operationen:\")\n",
    "print(\"Addition: \\n\", torch.add(a,b), \"\\noder:\", a+b)\n",
    "print(\"*\"*60)\n",
    "print(\"Subtraktion:\\n\", torch.sub(a,b), \"\\noder:\", a-b)\n",
    "print(\"*\"*60)\n",
    "print(\"Multiplikation:\\n\", torch.mul(a,b), \"\\noder:\", a*b)\n",
    "print(\"*\"*60)\n",
    "print(\"Division:\\n\", torch.div(a,b), \"\\noder:\", a/b)\n",
    "print(\"*\"*60)\n",
    "print(\"IN-PLACE: \")\n",
    "print(a.add_(b)) #adds b to a\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing geht am besten mit [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "size mismatch, m1: [2 x 3], m2: [2 x 3] at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1533090265711\\work\\aten\\src\\th\\generic/THTensorMath.cpp:2070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[131., 167.],\n",
       "        [145., 166.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping mit view\n",
    "print(a.size(), b.size())\n",
    "try:\n",
    "    torch.mm(a,b)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "#Resizing    \n",
    "b_view = b.view(3,2)\n",
    "torch.mm(a,b_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 NumPy Bridge\n",
    "- Umwandlung eines PyTorch-Tensors zu einem numpy-Array:\n",
    "    * Die Tensoren teilen den selben Speicherplatz. Änderungen beeinflussen beide Tensoren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "a: tensor([2., 2., 2., 2., 2.])\n",
      "b: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a, type(a))\n",
    "\n",
    "#Conversion zu einem numpy-Array\n",
    "b = a.numpy()\n",
    "print(b, type(b))\n",
    "\n",
    "#Sharing same memory locations --> Changes apply to each vector\n",
    "a.add_(1)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CUDA Tensors\n",
    "Tensoren können unter den Geräten mit der Methode `to()` geschoben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2490,  1.8078,  0.3414],\n",
      "        [ 0.7633,  1.7260,  0.4016],\n",
      "        [-0.2892,  0.4762,  1.6326],\n",
      "        [-0.7466,  0.8930, -0.8256],\n",
      "        [ 1.5493,  0.4598,  0.2259]], device='cuda:0')\n",
      "tensor([[ 1.2490,  1.8078,  0.3414],\n",
      "        [ 0.7633,  1.7260,  0.4016],\n",
      "        [-0.2892,  0.4762,  1.6326],\n",
      "        [-0.7466,  0.8930, -0.8256],\n",
      "        [ 1.5493,  0.4598,  0.2259]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA Tensors\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 [Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html): Automatische Differentierung un PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Package `torch.autograd` bietet eine automatische Differenzierung für alle Operationen an Tensoren. \n",
    "\n",
    "Notwendig sind folgende Objekte:\n",
    "- `torch.Tensor`-Objekte mit dem Attribut `requires_grad` auf `True` gesetzt. Am Ende einer Computation reicht es aus, die Methode `backward()` aufzurufen, damit alle Gradienten automatisch berechnet werden. Der Gradient von einem Tensor kann mit dem Attribut `grad` angesehen werden\n",
    "- `Funktion`-Objekte die mit Tensoren in einem Graphen verbunden sind. Jeder Tensor hat das Attribut `.grad_fn`, das eine Referenz auf die Funktion enthält, die den Tensor generiert hat).\n",
    "\n",
    "Beispiel aus der Übung:\n",
    "\n",
    "<img src=\"graph.png\" >\n",
    "\n",
    "* a = 2\n",
    "* b = e\n",
    "* c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True) tensor(2.7183, requires_grad=True) tensor(3., requires_grad=True)\n",
      "Variable a:  2.0\n"
     ]
    }
   ],
   "source": [
    "#Tensor deklariation\n",
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(np.e, requires_grad=True)\n",
    "c = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "print(a, b, c)\n",
    "#Wenn ein Tensor nur ein Element enthält, kann das Element mit .item() ausgegeben werden\n",
    "print(\"Variable a: \", a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None\n",
      "True True True\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad, c.grad)\n",
    "print(a.requires_grad, b.requires_grad, c.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyExerciseFunction(a,b,c):\n",
    "    ln = torch.log(b)\n",
    "    print(ln.grad_fn)\n",
    "    x = a + ln \n",
    "    print(x.grad_fn)\n",
    "    x = c * x\n",
    "    print(x.grad_fn)\n",
    "    x = (1./3.)*x\n",
    "    print(x.grad_fn)\n",
    "    out = 1./x\n",
    "    print(out.grad_fn)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LogBackward object at 0x0000022493DD7C50>\n",
      "<ThAddBackward object at 0x0000022493DD7C50>\n",
      "<ThMulBackward object at 0x0000022493DD7C50>\n",
      "<MulBackward object at 0x0000022493DD7C50>\n",
      "<MulBackward object at 0x0000022493DD7C50>\n",
      "Ergebnis aus Fowardpass:  0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "out =  applyExerciseFunction(a,b,c) #1/3\n",
    "print(\"Ergebnis aus Fowardpass: \", out.item()) #1./3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout/da:  tensor(-0.1111)\n",
      "dout/db:  tensor(-0.0409)\n",
      "dout/dc:  tensor(-0.1111)\n"
     ]
    }
   ],
   "source": [
    "print(\"dout/da: \", a.grad)\n",
    "print(\"dout/db: \", b.grad)\n",
    "print(\"dout/dc: \", c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Ausschalten der Gradienten:\n",
    "print(a.requires_grad)\n",
    "print((a ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((a ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neuronale Netze in PyTorch: `torch.nn` und `torchvision`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Package [`torch.nn`](https://pytorch.org/docs/stable/nn.html#)\n",
    "\n",
    "Neuronale Netze können in PyTorch einfach mit dem Objekten und Funktionen aus dem Modul `torch.nn` erzeugt werden.\n",
    "\n",
    "Das Package bietet Klassen für \n",
    "* die allgemeine Definition eines Modells (sog. [Container](https://pytorch.org/docs/stable/nn.html#containers)), wie `nn.Module`, sowie dessen \n",
    "* Layers, \n",
    "* Aktivierungsfunktionen, \n",
    "* Kostenfuntkionen ([Loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
    "\n",
    "Optimizer sind im Package [`torch.optim`](https://pytorch.org/docs/stable/optim.html#module-torch.optim) zu finden.\n",
    "Funktionen sind auch im Package `torch.nn.functional` verfügbar.\n",
    "Ein `nn.Module` enthält die Methode `forward(input)`, die das Ergebnis berechnet.\n",
    "\n",
    "\n",
    "### Das Package `torchvision`\n",
    "\n",
    "Viele Datensätze sind mit dem Package [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision-datasets) verfügbar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 FeedForward-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 MNIST-Datensatz vorbereiten\n",
    "\n",
    "Folgendes Beispiel implementiert ein FeedForward-Network für die Klassifizierung der Bilder aus dem MNIST-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dataset.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datensatz iterierbar machen\n",
    "Da wir 60000 Trainingsproben (Bilder) haben, müssen wir sie in kleine Gruppen (Batches) aufteilen und diese Batches an unser Feedforward Neural Network übergeben. \n",
    "Bei einer Batchgröße von 100, werden dem Modell bei jeder Iteration 600 Bilder übergeben.\n",
    "\n",
    "Eine Epoche bedeutet, dass das gesamte Trainingsset mit 60.000 Bildern erfolgreich an das Modell übergeben wurde: Eine Epoche besteht aus 600 Iterationen. \n",
    "\n",
    "Wenn wir den gesamten Datensatz 5 mal (5 Epochen) durchgehen wollen, damit das Modell lernt, dann sind 3000 Iterationen (600 x 5) notwendig. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Netzklasse mit `nn.Module` definieren\n",
    "\n",
    "PyTorch bietet viele Möglichkeiten, um ein Netz zu definieren. Hier leitet die Netzklasse aus dem Modul `nn.Module` ab. Sie definiert im Konsktruktor die notwendigen Layer sowie die Aktivierungsfunktion (== die Struktur) und in der Methode `forward()` die Schritte zum Ergebnis.\n",
    "\n",
    "Netzstruktur:\n",
    "- 3 fully connected Layers: Input-Layer, Hidden Layer, Output Layer\n",
    "- ReLU als Aktivierungsfunktion\n",
    "\n",
    "Eine Liste von weiteren Aktivierungsfunktionen ist [hier](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) verfügbar.\n",
    "\n",
    "Weitere Beispiele zur Definiton von einer Netzklasse:\n",
    "- PyTorch-Doku: https://pytorch.org/docs/stable/nn.html#\n",
    "- Udacity \"Neural Networks with PyTorch\" (Jupyter Notebook):  \n",
    "https://github.com/udacity/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%202%20-%20Neural%20Networks%20in%20PyTorch%20(Solution).ipynb\n",
    "\n",
    "Die Implementierung von diesem Netz erfolgte in Anlehnung zu folgenden Quellen:\n",
    "- Udacity Tutorial\n",
    "- Deep Learning Wizard: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/\n",
    "- Github-Repo: https://github.com/fawazsammani/The-Complete-Neural-Networks-Bootcamp-Theory-Applications/blob/master/Feed%20Forward%20Neural%20Network%20MNIST.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function  # LINEAR\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellklasse instanzieren\n",
    "\n",
    "- Input dimension: 784\n",
    "    * Size of image\n",
    "        * 28×28=784\n",
    "- Output dimension: 10 (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)    \n",
    "\n",
    "- Hidden dimension: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "- Feedforward Neural Network: **Cross Entropy Loss**\n",
    "    - Berechnung des Fehlers zwishen den softmax output und den Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "- Stochastich Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter von einem Netz untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# FC 2 Parameters\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# FC 2 Bias Parameters\n",
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übersicht\n",
    "\n",
    "<img src=\"nn1_params3.png\" >\n",
    "\n",
    "Quelle: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/\n",
    "\n",
    "1. Yellow box: Lineare Transformation auf dem Input $\\boldsymbol{y} = W\\boldsymbol{x} + \\boldsymbol{b}$\n",
    "2. Pink box: Logits werden einer nichtlinearen Funktion übergeben \n",
    "3. Blue box: Lineare Transformation auf dem Output\n",
    "4. Red box: Wahrscheinlichkeiten\n",
    "5. Purple box: Loss berechnen mit Cross Entropy Funktion\n",
    "\n",
    "Achtung: \n",
    "- Die `CrossEntropyLoss`-Funktion in PyTorch berechnet automatisch die Softmax-Werte. Deswegen muss man beim letzten Schritt im Forward-Pass kein Softmax berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell trainieren\n",
    "\n",
    "1. Input zu Tensoren umwandeln mit requires_grad \n",
    "2. Gradient-Buffer zurücksetzen: `zero_grad()`\n",
    "3. Berechnung des Outputs \n",
    "4. Berechnung des Fehlers durch Anwendung des `criterion` auf die berechneten Ergebnisse und bestehenden Labels\n",
    "5. Berechnung der Gradienten bezüglich der Parameter: `backward()`\n",
    "6. Parameter über den Optimizer aktualisieren: `step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.606570839881897. Accuracy: 86.46%\n",
      "Iteration: 1000. Loss: 0.4626705050468445. Accuracy: 89.48%\n",
      "Iteration: 1500. Loss: 0.3501792252063751. Accuracy: 90.28%\n",
      "Iteration: 2000. Loss: 0.3461214005947113. Accuracy: 91.24%\n",
      "Iteration: 2500. Loss: 0.18066388368606567. Accuracy: 91.64%\n",
      "Iteration: 3000. Loss: 0.2540605068206787. Accuracy: 91.99%\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step() #parameters = parameters - learning_rate * parameters_gradients\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "    \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell B: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 500. Loss: 0.21741831302642822. Accuracy: 91.68%\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 1000. Loss: 0.22004802525043488. Accuracy: 93.21%\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 1500. Loss: 0.24227432906627655. Accuracy: 94.01%\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 2000. Loss: 0.09125128388404846. Accuracy: 94.64%\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 2500. Loss: 0.159714475274086. Accuracy: 95.33%\n",
      "100\n",
      "0\n",
      "100\n",
      "100\n",
      "100\n",
      "200\n",
      "100\n",
      "300\n",
      "100\n",
      "400\n",
      "100\n",
      "500\n",
      "100\n",
      "600\n",
      "100\n",
      "700\n",
      "100\n",
      "800\n",
      "100\n",
      "900\n",
      "100\n",
      "1000\n",
      "100\n",
      "1100\n",
      "100\n",
      "1200\n",
      "100\n",
      "1300\n",
      "100\n",
      "1400\n",
      "100\n",
      "1500\n",
      "100\n",
      "1600\n",
      "100\n",
      "1700\n",
      "100\n",
      "1800\n",
      "100\n",
      "1900\n",
      "100\n",
      "2000\n",
      "100\n",
      "2100\n",
      "100\n",
      "2200\n",
      "100\n",
      "2300\n",
      "100\n",
      "2400\n",
      "100\n",
      "2500\n",
      "100\n",
      "2600\n",
      "100\n",
      "2700\n",
      "100\n",
      "2800\n",
      "100\n",
      "2900\n",
      "100\n",
      "3000\n",
      "100\n",
      "3100\n",
      "100\n",
      "3200\n",
      "100\n",
      "3300\n",
      "100\n",
      "3400\n",
      "100\n",
      "3500\n",
      "100\n",
      "3600\n",
      "100\n",
      "3700\n",
      "100\n",
      "3800\n",
      "100\n",
      "3900\n",
      "100\n",
      "4000\n",
      "100\n",
      "4100\n",
      "100\n",
      "4200\n",
      "100\n",
      "4300\n",
      "100\n",
      "4400\n",
      "100\n",
      "4500\n",
      "100\n",
      "4600\n",
      "100\n",
      "4700\n",
      "100\n",
      "4800\n",
      "100\n",
      "4900\n",
      "100\n",
      "5000\n",
      "100\n",
      "5100\n",
      "100\n",
      "5200\n",
      "100\n",
      "5300\n",
      "100\n",
      "5400\n",
      "100\n",
      "5500\n",
      "100\n",
      "5600\n",
      "100\n",
      "5700\n",
      "100\n",
      "5800\n",
      "100\n",
      "5900\n",
      "100\n",
      "6000\n",
      "100\n",
      "6100\n",
      "100\n",
      "6200\n",
      "100\n",
      "6300\n",
      "100\n",
      "6400\n",
      "100\n",
      "6500\n",
      "100\n",
      "6600\n",
      "100\n",
      "6700\n",
      "100\n",
      "6800\n",
      "100\n",
      "6900\n",
      "100\n",
      "7000\n",
      "100\n",
      "7100\n",
      "100\n",
      "7200\n",
      "100\n",
      "7300\n",
      "100\n",
      "7400\n",
      "100\n",
      "7500\n",
      "100\n",
      "7600\n",
      "100\n",
      "7700\n",
      "100\n",
      "7800\n",
      "100\n",
      "7900\n",
      "100\n",
      "8000\n",
      "100\n",
      "8100\n",
      "100\n",
      "8200\n",
      "100\n",
      "8300\n",
      "100\n",
      "8400\n",
      "100\n",
      "8500\n",
      "100\n",
      "8600\n",
      "100\n",
      "8700\n",
      "100\n",
      "8800\n",
      "100\n",
      "8900\n",
      "100\n",
      "9000\n",
      "100\n",
      "9100\n",
      "100\n",
      "9200\n",
      "100\n",
      "9300\n",
      "100\n",
      "9400\n",
      "100\n",
      "9500\n",
      "100\n",
      "9600\n",
      "100\n",
      "9700\n",
      "100\n",
      "9800\n",
      "100\n",
      "9900\n",
      "Iteration: 3000. Loss: 0.18860995769500732. Accuracy: 95.78%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity\n",
    "        out = self.relu(out)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                print(labels.size(0))\n",
    "                print(total)\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                ######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model C: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)\n",
    "\n",
    "<img src=\"nn2.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.24176952242851257. Accuracy: 90.98%\n",
      "Iteration: 1000. Loss: 0.1572435051202774. Accuracy: 93.58%\n",
      "Iteration: 1500. Loss: 0.17064525187015533. Accuracy: 94.84%\n",
      "Iteration: 2000. Loss: 0.1974581927061081. Accuracy: 95.60%\n",
      "Iteration: 2500. Loss: 0.1180160716176033. Accuracy: 96.00%\n",
      "Iteration: 3000. Loss: 0.11274317651987076. Accuracy: 96.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3 (readout): 100 --> 10\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 3 (readout)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784        #Number of input neurons (image pixels)\n",
    "hidden_size = 400       #Number of hidden neurons\n",
    "out_size = 10           #Number of classes (0-9) \n",
    "epochs = 15             #How many times we pass our entire dataset into our network \n",
    "batch_size = 100        #Input size of the data during one iteration \n",
    "learning_rate = 0.01   #How fast we are learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(nn.Module):\n",
    "    \"\"\"def __init__(self, input_size, hidden_size, out_size):\n",
    "        super(FFNet, self).__init__()                    \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)    #First Layer\n",
    "        self.relu = nn.ReLU()                            #First Layer Activation \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)   #Second Layer\n",
    "        self.fc3 = nn.Linear(hidden_size, out_size)      #Second Layer Activation \n",
    "    \n",
    "    def forward(self, x):                                #Forward Propagate \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256) #Input Layer\n",
    "        self.fc2 = nn.Linear(256, 128) #1st hidden Layer\n",
    "        self.fc3 = nn.Linear(128, 64) #2nd hidden Layer\n",
    "        self.fc4 = nn.Linear(64, 10) #Output layer\n",
    "        #Aktivierungsfunktion\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        #x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Netz initialisieren, Loss-Kriterium und Optimiser festlgegen:\n",
    "\n",
    "- Loss-Kriterium:\n",
    "    - [`CrossEntropyLoss()`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss): In PyTorch berechnet das Modul CrossEntropyLoss Softmax für die Eingabe. Deswegen braucht man im Forwardpass beim letzten Schritt kein softmax zu berechnen.\n",
    "- Optimizer: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Objekt initialisieren\n",
    "net = FFNet(input_size, hidden_size, out_size)\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    net = net.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Optimizer ist stochastic gradient descent\n",
    "#Parameter: Network-parameters, learning rate\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate) \"\"\"\n",
    "\n",
    "net = FFNet()\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    net = net.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNet(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "<bound method Module.parameters of FFNet(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "#Netz-Beschreibung\n",
    "print(net)\n",
    "#oder\n",
    "print(net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0993, -0.1937, -0.0627, -0.1156, -0.0860, -0.0180,  0.0204, -0.1012,\n",
      "          0.0941,  0.0929]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "if CUDA:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "output = net(images)\n",
    "#print(output[:10])\n",
    "# Get the class probabilities\n",
    "#ps = torch.exp(model(images))\n",
    "print(output[:1])\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0941],\n",
      "        [0.1262],\n",
      "        [0.0882],\n",
      "        [0.0996],\n",
      "        [0.0747],\n",
      "        [0.0958],\n",
      "        [0.0831],\n",
      "        [0.1025],\n",
      "        [0.0965],\n",
      "        [0.1019],\n",
      "        [0.0694],\n",
      "        [0.0801],\n",
      "        [0.1145],\n",
      "        [0.1008],\n",
      "        [0.0815],\n",
      "        [0.0834],\n",
      "        [0.0861],\n",
      "        [0.1161],\n",
      "        [0.1159],\n",
      "        [0.1036],\n",
      "        [0.1045],\n",
      "        [0.1066],\n",
      "        [0.0764],\n",
      "        [0.0728],\n",
      "        [0.0802],\n",
      "        [0.0713],\n",
      "        [0.1047],\n",
      "        [0.0923],\n",
      "        [0.0990],\n",
      "        [0.0837],\n",
      "        [0.0909],\n",
      "        [0.0873],\n",
      "        [0.0926],\n",
      "        [0.0985],\n",
      "        [0.1110],\n",
      "        [0.0678],\n",
      "        [0.1130],\n",
      "        [0.0832],\n",
      "        [0.0765],\n",
      "        [0.0846],\n",
      "        [0.0691],\n",
      "        [0.1027],\n",
      "        [0.0813],\n",
      "        [0.0950],\n",
      "        [0.1053],\n",
      "        [0.0895],\n",
      "        [0.0916],\n",
      "        [0.1055],\n",
      "        [0.0949],\n",
      "        [0.0995],\n",
      "        [0.0898],\n",
      "        [0.1190],\n",
      "        [0.0955],\n",
      "        [0.0885],\n",
      "        [0.0956],\n",
      "        [0.1027],\n",
      "        [0.0983],\n",
      "        [0.0802],\n",
      "        [0.1080],\n",
      "        [0.0829],\n",
      "        [0.0958],\n",
      "        [0.1118],\n",
      "        [0.1051],\n",
      "        [0.0877]], device='cuda:0', grad_fn=<TopkBackward>)\n",
      "tensor([[8],\n",
      "        [9],\n",
      "        [8],\n",
      "        [9],\n",
      "        [8],\n",
      "        [8],\n",
      "        [9],\n",
      "        [8],\n",
      "        [8],\n",
      "        [8]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = output.topk(1, dim=1)\n",
    "print(top_p)\n",
    "# Look at the most likely classes for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.5625%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "keineAhnung, predicted = torch.max(outputs.data, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 0, 5, 0, 7, 8, 9, 0, 1, 2, 3, 0, 5, 0], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFNet trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.492..  Test Loss: 0.522..  Test Accuracy: 78.000\n",
      "Epoch: 2/10..  Training Loss: 0.490..  Test Loss: 0.524..  Test Accuracy: 78.000\n",
      "Epoch: 3/10..  Training Loss: 0.489..  Test Loss: 0.519..  Test Accuracy: 78.000\n",
      "Epoch: 4/10..  Training Loss: 0.487..  Test Loss: 0.521..  Test Accuracy: 78.000\n",
      "Epoch: 5/10..  Training Loss: 0.485..  Test Loss: 0.519..  Test Accuracy: 78.000\n",
      "Epoch: 6/10..  Training Loss: 0.484..  Test Loss: 0.528..  Test Accuracy: 78.000\n",
      "Epoch: 7/10..  Training Loss: 0.483..  Test Loss: 0.522..  Test Accuracy: 78.000\n",
      "Epoch: 8/10..  Training Loss: 0.481..  Test Loss: 0.518..  Test Accuracy: 79.000\n",
      "Epoch: 9/10..  Training Loss: 0.480..  Test Loss: 0.522..  Test Accuracy: 78.000\n",
      "Epoch: 10/10..  Training Loss: 0.479..  Test Loss: 0.525..  Test Accuracy: 78.000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(images)                             # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "       \n",
    "        total_train += labels.size(0) \n",
    "        if CUDA:\n",
    "            correct_train += (predicted.cpu() == labels.cpu()).sum() \n",
    "        else:\n",
    "            correct_train += (predicted == labels).sum() \n",
    "            \n",
    "        loss = criterion(outputs, labels)                 # Difference between the actual and predicted (loss function)\n",
    "        loss.backward()                                   # Backpropagation\n",
    "        optimizer.step()            \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        ###\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                if CUDA:\n",
    "                    images = images.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                outputs = net(images) \n",
    "                _, predicted = torch.max(outputs.data, 1) \n",
    "                total += labels.size(0) # Increment the total count (100)\n",
    "                \n",
    "                if CUDA:\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()    \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum() \n",
    "                    \n",
    "                test_loss += criterion(outputs, labels)\n",
    "           \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {}%\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2248c67af60>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 380
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Iteration [100/600], Training Loss: 1.8407481908798218, Training Accuracy: 51%\n",
      "Epoch [1/15], Iteration [200/600], Training Loss: 0.8517826199531555, Training Accuracy: 63%\n",
      "Epoch [1/15], Iteration [300/600], Training Loss: 0.6758299469947815, Training Accuracy: 70%\n",
      "Epoch [1/15], Iteration [400/600], Training Loss: 0.4399491250514984, Training Accuracy: 74%\n",
      "Epoch [1/15], Iteration [500/600], Training Loss: 0.4819956123828888, Training Accuracy: 76%\n",
      "Epoch [1/15], Iteration [600/600], Training Loss: 0.2581551671028137, Training Accuracy: 78%\n",
      "Epoch [2/15], Iteration [100/600], Training Loss: 0.34013375639915466, Training Accuracy: 80%\n",
      "Epoch [2/15], Iteration [200/600], Training Loss: 0.43181464076042175, Training Accuracy: 81%\n",
      "Epoch [2/15], Iteration [300/600], Training Loss: 0.22752182185649872, Training Accuracy: 82%\n",
      "Epoch [2/15], Iteration [400/600], Training Loss: 0.3089792728424072, Training Accuracy: 83%\n",
      "Epoch [2/15], Iteration [500/600], Training Loss: 0.27360111474990845, Training Accuracy: 83%\n",
      "Epoch [2/15], Iteration [600/600], Training Loss: 0.21763673424720764, Training Accuracy: 84%\n",
      "Epoch [3/15], Iteration [100/600], Training Loss: 0.41119739413261414, Training Accuracy: 84%\n",
      "Epoch [3/15], Iteration [200/600], Training Loss: 0.22535133361816406, Training Accuracy: 85%\n",
      "Epoch [3/15], Iteration [300/600], Training Loss: 0.29555949568748474, Training Accuracy: 85%\n",
      "Epoch [3/15], Iteration [400/600], Training Loss: 0.22493913769721985, Training Accuracy: 86%\n",
      "Epoch [3/15], Iteration [500/600], Training Loss: 0.3437659740447998, Training Accuracy: 86%\n",
      "Epoch [3/15], Iteration [600/600], Training Loss: 0.18225334584712982, Training Accuracy: 86%\n",
      "Epoch [4/15], Iteration [100/600], Training Loss: 0.41670092940330505, Training Accuracy: 87%\n",
      "Epoch [4/15], Iteration [200/600], Training Loss: 0.32615506649017334, Training Accuracy: 87%\n",
      "Epoch [4/15], Iteration [300/600], Training Loss: 0.2139066904783249, Training Accuracy: 87%\n",
      "Epoch [4/15], Iteration [400/600], Training Loss: 0.27355679869651794, Training Accuracy: 87%\n",
      "Epoch [4/15], Iteration [500/600], Training Loss: 0.2806033492088318, Training Accuracy: 88%\n",
      "Epoch [4/15], Iteration [600/600], Training Loss: 0.21154826879501343, Training Accuracy: 88%\n",
      "Epoch [5/15], Iteration [100/600], Training Loss: 0.21366578340530396, Training Accuracy: 88%\n",
      "Epoch [5/15], Iteration [200/600], Training Loss: 0.12932509183883667, Training Accuracy: 88%\n",
      "Epoch [5/15], Iteration [300/600], Training Loss: 0.25465288758277893, Training Accuracy: 88%\n",
      "Epoch [5/15], Iteration [400/600], Training Loss: 0.34499451518058777, Training Accuracy: 89%\n",
      "Epoch [5/15], Iteration [500/600], Training Loss: 0.5300629734992981, Training Accuracy: 89%\n",
      "Epoch [5/15], Iteration [600/600], Training Loss: 0.26388031244277954, Training Accuracy: 89%\n",
      "Epoch [6/15], Iteration [100/600], Training Loss: 0.21632757782936096, Training Accuracy: 89%\n",
      "Epoch [6/15], Iteration [200/600], Training Loss: 0.27774766087532043, Training Accuracy: 89%\n",
      "Epoch [6/15], Iteration [300/600], Training Loss: 0.2530358135700226, Training Accuracy: 89%\n",
      "Epoch [6/15], Iteration [400/600], Training Loss: 0.18978893756866455, Training Accuracy: 89%\n",
      "Epoch [6/15], Iteration [500/600], Training Loss: 0.19612978398799896, Training Accuracy: 90%\n",
      "Epoch [6/15], Iteration [600/600], Training Loss: 0.09599249064922333, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [100/600], Training Loss: 0.16823464632034302, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [200/600], Training Loss: 0.28264182806015015, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [300/600], Training Loss: 0.19033752381801605, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [400/600], Training Loss: 0.16166993975639343, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [500/600], Training Loss: 0.09227573126554489, Training Accuracy: 90%\n",
      "Epoch [7/15], Iteration [600/600], Training Loss: 0.13759395480155945, Training Accuracy: 90%\n",
      "Epoch [8/15], Iteration [100/600], Training Loss: 0.12462154030799866, Training Accuracy: 91%\n",
      "Epoch [8/15], Iteration [200/600], Training Loss: 0.23322682082653046, Training Accuracy: 91%\n",
      "Epoch [8/15], Iteration [300/600], Training Loss: 0.10306742042303085, Training Accuracy: 91%\n",
      "Epoch [8/15], Iteration [400/600], Training Loss: 0.17071494460105896, Training Accuracy: 91%\n",
      "Epoch [8/15], Iteration [500/600], Training Loss: 0.14827367663383484, Training Accuracy: 91%\n",
      "Epoch [8/15], Iteration [600/600], Training Loss: 0.1185549795627594, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [100/600], Training Loss: 0.1857607662677765, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [200/600], Training Loss: 0.09684137254953384, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [300/600], Training Loss: 0.2237645983695984, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [400/600], Training Loss: 0.10063008964061737, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [500/600], Training Loss: 0.16858543455600739, Training Accuracy: 91%\n",
      "Epoch [9/15], Iteration [600/600], Training Loss: 0.17205345630645752, Training Accuracy: 91%\n",
      "Epoch [10/15], Iteration [100/600], Training Loss: 0.10878226161003113, Training Accuracy: 91%\n",
      "Epoch [10/15], Iteration [200/600], Training Loss: 0.177223339676857, Training Accuracy: 92%\n",
      "Epoch [10/15], Iteration [300/600], Training Loss: 0.15769562125205994, Training Accuracy: 92%\n",
      "Epoch [10/15], Iteration [400/600], Training Loss: 0.08810050785541534, Training Accuracy: 92%\n",
      "Epoch [10/15], Iteration [500/600], Training Loss: 0.09974922239780426, Training Accuracy: 92%\n",
      "Epoch [10/15], Iteration [600/600], Training Loss: 0.1736072599887848, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [100/600], Training Loss: 0.12359029799699783, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [200/600], Training Loss: 0.12233930826187134, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [300/600], Training Loss: 0.20403774082660675, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [400/600], Training Loss: 0.2842710614204407, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [500/600], Training Loss: 0.05080254003405571, Training Accuracy: 92%\n",
      "Epoch [11/15], Iteration [600/600], Training Loss: 0.07537885010242462, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [100/600], Training Loss: 0.07137449830770493, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [200/600], Training Loss: 0.09667634963989258, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [300/600], Training Loss: 0.23564863204956055, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [400/600], Training Loss: 0.06796834617853165, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [500/600], Training Loss: 0.08615719527006149, Training Accuracy: 92%\n",
      "Epoch [12/15], Iteration [600/600], Training Loss: 0.05327274277806282, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [100/600], Training Loss: 0.16016939282417297, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [200/600], Training Loss: 0.07333783805370331, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [300/600], Training Loss: 0.0795401856303215, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [400/600], Training Loss: 0.09834622591733932, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [500/600], Training Loss: 0.04634104669094086, Training Accuracy: 93%\n",
      "Epoch [13/15], Iteration [600/600], Training Loss: 0.07818063348531723, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [100/600], Training Loss: 0.11915285885334015, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [200/600], Training Loss: 0.12710510194301605, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [300/600], Training Loss: 0.053618863224983215, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [400/600], Training Loss: 0.166234090924263, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [500/600], Training Loss: 0.20696276426315308, Training Accuracy: 93%\n",
      "Epoch [14/15], Iteration [600/600], Training Loss: 0.08602332323789597, Training Accuracy: 93%\n",
      "Epoch [15/15], Iteration [100/600], Training Loss: 0.06977131217718124, Training Accuracy: 93%\n",
      "Epoch [15/15], Iteration [200/600], Training Loss: 0.10202278196811676, Training Accuracy: 93%\n",
      "Epoch [15/15], Iteration [300/600], Training Loss: 0.08932716399431229, Training Accuracy: 93%\n",
      "Epoch [15/15], Iteration [400/600], Training Loss: 0.11030415445566177, Training Accuracy: 93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Iteration [500/600], Training Loss: 0.14589154720306396, Training Accuracy: 93%\n",
      "Epoch [15/15], Iteration [600/600], Training Loss: 0.09284001588821411, Training Accuracy: 93%\n",
      "DONE TRAINING!\n"
     ]
    }
   ],
   "source": [
    "#Netz trainieren\n",
    "#Train the network\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   \n",
    "        #Flatten the image from size (batch,1,28,28) --> (100,1,28,28) where 1 represents the number of channels (grayscale-->1),\n",
    "        # to size (100,784) and wrap it in a variable\n",
    "        images = images.view(-1, 28*28)   \n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        # Clear the param_grad in param = param - lr*param_grad, so it won't be accumulated\n",
    "        optimizer.zero_grad()                             \n",
    "        outputs = net(images)                             # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)         # Return the second argument of torch.max which represents \n",
    "                                                          # the index location of each maximum value found  \n",
    "        total_train += labels.size(0) \n",
    "        if CUDA:\n",
    "            correct_train += (predicted.cpu() == labels.cpu()).sum() \n",
    "        else:\n",
    "            correct_train += (predicted == labels).sum() \n",
    "          \n",
    "        loss = criterion(outputs, labels)                 # Difference between the actual and predicted (loss function)\n",
    "        loss.backward()                                   # Backpropagation\n",
    "        optimizer.step()                                  # Update the weights\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Printing the results \n",
    "            print('Epoch [{}/{}], Iteration [{}/{}], Training Loss: {}, Training Accuracy: {}%'.format\n",
    "                 (epoch+1, epochs, i+1, len(train_dataset)//batch_size, loss.data[0], (100*correct_train/total_train)))\n",
    "print(\"DONE TRAINING!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFNet testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 96 %\n"
     ]
    }
   ],
   "source": [
    "#Test the network (No loss and weight calculation, no weight update)\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    if CUDA:\n",
    "        images = images.cuda()\n",
    "    #For each input (sample/row) in the batch, the output will contain 10 elements\n",
    "    outputs = net(images)\n",
    "    #We could also write: predicted = outputs.data.max(1)[1]\n",
    "    _, predicted = torch.max(outputs.data, 1)  \n",
    "    total += labels.size(0) # Increment the total count (100)\n",
    "    #We can also use: correct += predicted.eq(labels).sum()\n",
    "    if CUDA:\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()    \n",
    "    else:\n",
    "        correct += (predicted == labels).sum()    \n",
    "    \n",
    "    \n",
    "print('Final Test Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Convolutional Neural Network  (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #Same Padding = [(filter size - 1) / 2] (Same Padding--> input size = output size)\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
    "        #The output size of each of the 8 feature maps is \n",
    "        #[(input_size - filter_size + 2(padding) / stride) +1] --> [(28-3+2(1)/1)+1] = 28 (padding type is same)\n",
    "        #Batch normalization\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        #RELU\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is now 28/2 = 14\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        #Output size of each of the 32 feature maps remains 14\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is 14/2 = 7\n",
    "        #Flatten the feature maps. You have 32 feature maps, each of them is of size 7x7 --> 32*7*7 = 1568\n",
    "        self.fc1 = nn.Linear(in_features=1568, out_features=600)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=10)\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #Now we have to flatten the output. This is where we apply the feed forward neural network as learned before! \n",
    "        #It will take the shape (batch_size, 1568) = (100, 1568)\n",
    "        out = out.view(-1,1568)\n",
    "        #Then we forward through our fully connected layer \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()    \n",
    "loss_fn = nn.CrossEntropyLoss()        \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.713, Training Accuracy: 81.00%, Testing Loss: 0.006, Testing Accuracy: 94.00%\n",
      "Epoch 2/10, Training Loss: 0.197, Training Accuracy: 94.00%, Testing Loss: 0.003, Testing Accuracy: 96.00%\n",
      "Epoch 3/10, Training Loss: 0.139, Training Accuracy: 95.00%, Testing Loss: 0.003, Testing Accuracy: 97.00%\n",
      "Epoch 4/10, Training Loss: 0.111, Training Accuracy: 96.00%, Testing Loss: 0.002, Testing Accuracy: 97.00%\n",
      "Epoch 5/10, Training Loss: 0.096, Training Accuracy: 97.00%, Testing Loss: 0.002, Testing Accuracy: 98.00%\n",
      "Epoch 6/10, Training Loss: 0.084, Training Accuracy: 97.00%, Testing Loss: 0.002, Testing Accuracy: 98.00%\n",
      "Epoch 7/10, Training Loss: 0.075, Training Accuracy: 97.00%, Testing Loss: 0.001, Testing Accuracy: 98.00%\n",
      "Epoch 8/10, Training Loss: 0.070, Training Accuracy: 97.00%, Testing Loss: 0.001, Testing Accuracy: 98.00%\n",
      "Epoch 9/10, Training Loss: 0.063, Training Accuracy: 98.00%, Testing Loss: 0.001, Testing Accuracy: 98.00%\n",
      "Epoch 10/10, Training Loss: 0.059, Training Accuracy: 98.00%, Testing Loss: 0.001, Testing Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "#Training the CNN\n",
    "num_epochs = 10\n",
    "\n",
    "#Define the lists to store the results of loss and accuracy\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#Training\n",
    "for epoch in range(num_epochs): \n",
    "    #Reset these below variables to 0 at the begining of every epoch\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    iter_loss = 0.0\n",
    "    \n",
    "    model.train()                   # Put the network into training mode\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # If we have GPU, shift the data to GPU\n",
    "        CUDA = torch.cuda.is_available()\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()            # Clear off the gradient in (w = w - gradient)\n",
    "        outputs = model(inputs)         \n",
    "        loss = loss_fn(outputs, labels)  \n",
    "        iter_loss += loss.data[0]       # Accumulate the loss\n",
    "        loss.backward()                 # Backpropagation \n",
    "        optimizer.step()                # Update the weights\n",
    "        \n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "    \n",
    "    # Record the training loss\n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(train_dataset)))\n",
    "   \n",
    "    #Testing\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()                    # Put the network into evaluation mode\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(inputs)     \n",
    "        loss = loss_fn(outputs, labels) # Calculate the loss\n",
    "        loss += loss.data[0]\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    # Record the Testing loss\n",
    "    test_loss.append(loss/iterations)\n",
    "    # Record the Testing accuracy\n",
    "    test_accuracy.append((100 * correct / len(test_dataset)))\n",
    "    \n",
    "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.2f}%, Testing Loss: {:.3f}, Testing Accuracy: {:.2f}%'\n",
    "           .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], \n",
    "             test_loss[-1], test_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8997\n",
      "tensor([[ 1.2415, -3.2654, -0.0837, -3.0032,  2.2969,  1.8857, 13.7696, -9.4470,\n",
      "          1.4453, -3.6773]], device='cuda:0', grad_fn=<ThAddmmBackward>)\n",
      "tensor([[ 1.2415, -3.2654, -0.0837, -3.0032,  2.2969,  1.8857, 13.7696, -9.4470,\n",
      "          1.4453, -3.6773]], device='cuda:0')\n",
      "Prediction is:  6\n",
      "Actual is is :  6\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "rand_idx = randint(0,10001)\n",
    "print(rand_idx)\n",
    "img = test_dataset[rand_idx][0].resize_((1, 1, 28, 28))   #(batch_size,channels,height,width)\n",
    "label = test_dataset[rand_idx][1]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "    img = img.cuda()\n",
    "    \n",
    "output = model(img)\n",
    "print(output)\n",
    "print(output.data)\n",
    "_, predicted = torch.max(output,1)\n",
    "print(\"Prediction is: \", predicted.item())\n",
    "print(\"Actual is is : \", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packt publishing\n",
    "def plot_img(image):\n",
    "    image = image.numpy()[0]\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    image = ((mean * image) + std)\n",
    "    plt.imshow(image,cmap='binary', interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen\n",
    "\n",
    "https://github.com/udacity/deep-learning-v2-pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
