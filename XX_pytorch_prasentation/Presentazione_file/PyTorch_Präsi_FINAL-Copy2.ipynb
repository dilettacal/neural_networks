{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - Vortrag\n",
    "### HTW Berlin - Angewandte Informatik (B. Sc.)\n",
    "#### Modul \"Ausgewählte Kapitel sozialer Webtechnologien\" (aka Neuronale Netze)\n",
    "\n",
    "##### Diletta Calussi - s0559842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhalte\n",
    "\n",
    "1. Das Framework PyTorch\n",
    "2. PyTorch Fundamentals (Warm-up)\n",
    "3. Neuronale Netze in PyTorch\n",
    "4. Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Das Framework [PyTorch](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eine ML Open-Source-Bibliothek für python\n",
    "- Basiert auf der in [**Lua**](https://www.lua.org/) geschriebenen Bibliothek [**Torch**](http://torch.ch/)\n",
    "- Vom Facebook-Forschungsteam für K.I. entwickelt \n",
    "- Erscheinungsjahr: 2016\n",
    "- Unterstützt GPU sowie CPU \n",
    "- High Level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurze Übersicht\n",
    "\n",
    "1. Tensoren\n",
    "2. Dynamische Graphen (Dynamic Computational Graph)\n",
    "3. Autograd-System zur Berechnung der Ableitungen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages für diese Präsentation\n",
    "- torch (CUDA oder GPU)\n",
    "- torchvision\n",
    "- numpy\n",
    "\n",
    "\n",
    "\n",
    "Eine Anleitung für die Installation ist auf der Webseite von [PyTorch](https://pytorch.org/) verfügbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 0.4.1\n",
      "CUDA is active: True\n",
      "CUDA version: 8.0\n"
     ]
    }
   ],
   "source": [
    "#Installation check\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA is active:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch Fundamentals (Warm-up)\n",
    "\n",
    "PyTorch bietet zwei Abstraktionen für Datenstrukturen: Tensoren und Variablen. Tensoren sind so ähnlich wie NumPy-Arrays und können auch auf GPUs übertragen werden. Variablen waren bis zur Version 0.4. als Wrapper um Tensoren notwendig, um bsp. die Berechnung der Gradienten zu ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tensoren\n",
    "\n",
    "Ein `torch.Tensor` ist eine mehrdimensionale Matrix, die Elemente von einem bestimmten Datentyp enthält. Ein detaillierter Überblick der unterstützten Datentype ist auf der [Webseite von PyTorch](https://pytorch.org/docs/stable/tensors.html) verfügbar.  \n",
    "\n",
    "PyTorch unterstützt sowohl GPU- als auch CPU-Tensoren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispiele aus der [PyTorch-Webseite](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 2.3098e-14],\n",
      "        [8.6740e-43, 2.8026e-45, 1.9180e+08],\n",
      "        [3.2641e-28, 8.0419e-40, 1.7045e-24],\n",
      "        [2.8026e-45, 1.9946e-14, 8.6740e-43],\n",
      "        [1.4013e-45, 0.0000e+00, 3.6183e-15]])\n",
      "tensor([[0.9120, 0.1146, 0.7886],\n",
      "        [0.2711, 0.1704, 0.7164],\n",
      "        [0.4287, 0.4288, 0.9780],\n",
      "        [0.9754, 0.3429, 0.5061],\n",
      "        [0.7708, 0.8438, 0.1262]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([5.5000, 3.0000])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-2.0859, -1.4002, -0.6456],\n",
      "        [-0.5518,  0.6765,  0.9266],\n",
      "        [ 0.1259, -1.0140, -1.6901],\n",
      "        [ 0.9061, -0.4135,  2.6784],\n",
      "        [-0.7213, -0.9194,  0.9348]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "#5x3 matrix, nicht initialisiert\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "#Random-Initialisierung\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "#Matrix filled with zeros mit Typ Long\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "#Tensor aus Daten\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)\n",
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operationen auf Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 6., 1.],\n",
      "        [6., 4., 2.]])\n",
      "\n",
      "tensor([[8., 8., 2.],\n",
      "        [6., 8., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(1,10,(2,3))\n",
    "b = torch.randint(1,10,(2,3))\n",
    "print(a)\n",
    "print()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise-Operationen:\n",
      "Addition: \n",
      " tensor([[10., 14.,  3.],\n",
      "        [12., 12.,  4.]]) \n",
      "oder: tensor([[10., 14.,  3.],\n",
      "        [12., 12.,  4.]])\n",
      "************************************************************\n",
      "Subtraktion:\n",
      " tensor([[-6., -2., -1.],\n",
      "        [ 0., -4.,  0.]]) \n",
      "oder: tensor([[-6., -2., -1.],\n",
      "        [ 0., -4.,  0.]])\n",
      "************************************************************\n",
      "Multiplikation:\n",
      " tensor([[16., 48.,  2.],\n",
      "        [36., 32.,  4.]]) \n",
      "oder: tensor([[16., 48.,  2.],\n",
      "        [36., 32.,  4.]])\n",
      "************************************************************\n",
      "Division:\n",
      " tensor([[0.2500, 0.7500, 0.5000],\n",
      "        [1.0000, 0.5000, 1.0000]]) \n",
      "oder: tensor([[0.2500, 0.7500, 0.5000],\n",
      "        [1.0000, 0.5000, 1.0000]])\n",
      "************************************************************\n",
      "IN-PLACE: \n",
      "tensor([[10., 14.,  3.],\n",
      "        [12., 12.,  4.]])\n",
      "tensor([[10., 14.,  3.],\n",
      "        [12., 12.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "#Elementwise Operationen (mit den Funktionen .add(), .sub(), .mul(), .div())\n",
    "print(\"Elementwise-Operationen:\")\n",
    "print(\"Addition: \\n\", torch.add(a,b), \"\\noder:\", a+b)\n",
    "print(\"*\"*60)\n",
    "print(\"Subtraktion:\\n\", torch.sub(a,b), \"\\noder:\", a-b)\n",
    "print(\"*\"*60)\n",
    "print(\"Multiplikation:\\n\", torch.mul(a,b), \"\\noder:\", a*b)\n",
    "print(\"*\"*60)\n",
    "print(\"Division:\\n\", torch.div(a,b), \"\\noder:\", a/b)\n",
    "print(\"*\"*60)\n",
    "print(\"IN-PLACE: \")\n",
    "print(a.add_(b)) #adds b to a\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing geht am besten mit [`view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "size mismatch, m1: [2 x 3], m2: [2 x 3] at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1533090265711\\work\\aten\\src\\th\\generic/THTensorMath.cpp:2070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[132., 170.],\n",
       "        [152., 176.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping mit view\n",
    "print(a.size(), b.size())\n",
    "try:\n",
    "    torch.mm(a,b)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "#Resizing    \n",
    "b_view = b.view(3,2)\n",
    "torch.mm(a,b_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 NumPy Bridge\n",
    "- Umwandlung eines PyTorch-Tensors zu einem numpy-Array:\n",
    "    * Die Tensoren teilen den selben Speicherplatz. Änderungen beeinflussen beide Tensoren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
      "b: [1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "a: tensor([2., 2., 2., 2., 2.])\n",
      "b: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(\"a:\",a, type(a))\n",
    "\n",
    "#Conversion zu einem numpy-Array\n",
    "b = a.numpy()\n",
    "print(\"b:\", b, type(b))\n",
    "\n",
    "#Sharing same memory locations --> Changes apply to each vector\n",
    "a.add_(1)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CUDA Tensors\n",
    "Tensoren können unter den Geräten mit der Methode `to()` geschoben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0859, -0.4002,  0.3544],\n",
      "        [ 0.4482,  1.6765,  1.9266],\n",
      "        [ 1.1259, -0.0140, -0.6901],\n",
      "        [ 1.9061,  0.5865,  3.6784],\n",
      "        [ 0.2787,  0.0806,  1.9348]], device='cuda:0')\n",
      "tensor([[-1.0859, -0.4002,  0.3544],\n",
      "        [ 0.4482,  1.6765,  1.9266],\n",
      "        [ 1.1259, -0.0140, -0.6901],\n",
      "        [ 1.9061,  0.5865,  3.6784],\n",
      "        [ 0.2787,  0.0806,  1.9348]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# CUDA Tensors\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 [Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html): Automatische Differentierung un PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Package `torch.autograd` bietet eine automatische Differenzierung für alle Operationen an Tensoren. \n",
    "\n",
    "Notwendig sind folgende Objekte:\n",
    "- `torch.Tensor`-Objekte mit dem Attribut `requires_grad` auf `True` gesetzt. Am Ende einer Computation reicht es aus, die Methode `backward()` aufzurufen, damit alle Gradienten automatisch berechnet werden. Der Gradient von einem Tensor kann mit dem Attribut `grad` angesehen werden\n",
    "- `Funktion`-Objekte die mit Tensoren in einem Graphen verbunden sind. Jeder Tensor hat das Attribut `.grad_fn`, das eine Referenz auf die Funktion enthält, die den Tensor generiert hat).\n",
    "\n",
    "Beispiel aus der Übung:\n",
    "\n",
    "<img src=\"graph.png\" >\n",
    "\n",
    "* a = 2\n",
    "* b = e\n",
    "* c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True) tensor(2.7183, requires_grad=True) tensor(3., requires_grad=True)\n",
      "Variable a:  2.0\n"
     ]
    }
   ],
   "source": [
    "#Tensor deklariation\n",
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(np.e, requires_grad=True)\n",
    "c = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "print(a, b, c)\n",
    "#Wenn ein Tensor nur ein Element enthält, kann das Element mit .item() ausgegeben werden\n",
    "print(\"Variable a: \", a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None\n",
      "True True True\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad, c.grad)\n",
    "print(a.requires_grad, b.requires_grad, c.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyExerciseFunction(a,b,c):\n",
    "    ln = torch.log(b)\n",
    "    print(ln.grad_fn)\n",
    "    x = a + ln \n",
    "    print(x.grad_fn)\n",
    "    x = c * x\n",
    "    print(x.grad_fn)\n",
    "    x = (1./3.)*x\n",
    "    print(x.grad_fn)\n",
    "    out = 1./x\n",
    "    print(out.grad_fn)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LogBackward object at 0x0000026B2AF4C2E8>\n",
      "<ThAddBackward object at 0x0000026B2AF4C2E8>\n",
      "<ThMulBackward object at 0x0000026B2AF4C2E8>\n",
      "<MulBackward object at 0x0000026B2AF4C2E8>\n",
      "<MulBackward object at 0x0000026B2AF4C2E8>\n",
      "Ergebnis aus Fowardpass:  0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "out =  applyExerciseFunction(a,b,c) #1/3\n",
    "print(\"Ergebnis aus Fowardpass: \", out.item()) #1./3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout/da:  tensor(-0.1111)\n",
      "dout/db:  tensor(-0.0409)\n",
      "dout/dc:  tensor(-0.1111)\n"
     ]
    }
   ],
   "source": [
    "print(\"dout/da: \", a.grad)\n",
    "print(\"dout/db: \", b.grad)\n",
    "print(\"dout/dc: \", c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Ausschalten der Gradienten:\n",
    "print(a.requires_grad)\n",
    "print((a ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((a ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neuronale Netze in PyTorch: `torch.nn` und `torchvision`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Package [`torch.nn`](https://pytorch.org/docs/stable/nn.html#)\n",
    "\n",
    "Neuronale Netze können in PyTorch einfach mit dem Objekten und Funktionen aus dem Modul `torch.nn` erzeugt werden.\n",
    "\n",
    "Das Package bietet Klassen für \n",
    "* die allgemeine Definition eines Modells (sog. [Container](https://pytorch.org/docs/stable/nn.html#containers)), wie `nn.Module`, sowie dessen \n",
    "* Layers, \n",
    "* Aktivierungsfunktionen, \n",
    "* Kostenfuntkionen ([Loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
    "\n",
    "Optimizer sind im Package [`torch.optim`](https://pytorch.org/docs/stable/optim.html#module-torch.optim) zu finden.\n",
    "Funktionen sind auch im Package `torch.nn.functional` verfügbar.\n",
    "Ein `nn.Module` enthält die Methode `forward(input)`, die das Ergebnis berechnet.\n",
    "\n",
    "\n",
    "### Das Package `torchvision`\n",
    "\n",
    "Viele Datensätze sind mit dem Package [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision-datasets) verfügbar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 FeedForward-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 MNIST-Datensatz vorbereiten\n",
    "\n",
    "Folgendes Beispiel implementiert ein FeedForward-Network für die Klassifizierung der Bilder aus dem MNIST-Datensatz.\n",
    "\n",
    "Folgendes Beispiel ist aus der Webseite \"Deep Learning Wizard\" übernommen: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dataset.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datensatz iterierbar machen\n",
    "\n",
    "- 60.000 Bilder (Trainingsproben)\n",
    "- Batches == 100 --> Kleine Gruppen von Bildern, die dem FFNN übergeben werden\n",
    "- Eine Epoche sieht immer also 600 Bilder\n",
    "- Wenn man den Datensatz 5x durchlaufen möchte, dann sind 3000 Iterationen notwendig (600x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size) #5\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Netzklasse mit `nn.Module` definieren\n",
    "\n",
    "PyTorch bietet viele Möglichkeiten, um ein Netz zu definieren. Hier leitet die Netzklasse aus dem Modul `nn.Module` ab. Sie definiert im Konsktruktor die notwendigen Layer sowie die Aktivierungsfunktion (== die Struktur) und in der Methode `forward()` die Schritte zum Ergebnis.\n",
    "\n",
    "Eine Liste von weiteren Aktivierungsfunktionen ist [hier](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) verfügbar.\n",
    "\n",
    "Weitere Beispiele zur Definiton von einer Netzklasse:\n",
    "- PyTorch-Doku: https://pytorch.org/docs/stable/nn.html#\n",
    "- Udacity \"Neural Networks with PyTorch\" (Jupyter Notebook):  \n",
    "https://github.com/udacity/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/Part%202%20-%20Neural%20Networks%20in%20PyTorch%20(Solution).ipynb\n",
    "\n",
    "Die Implementierung von diesem Netz erfolgte in Anlehnung zu folgender Quelle:\n",
    "- Deep Learning Wizard: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übersicht - Ein Bild\n",
    "\n",
    "<img src=\"nn1_params3.png\" >\n",
    "\n",
    "Quelle: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/\n",
    "\n",
    "1. Yellow box: Lineare Transformation auf dem Input $\\boldsymbol{y} = W\\boldsymbol{x} + \\boldsymbol{b}$\n",
    "2. Pink box: Logits werden einer nichtlinearen Funktion übergeben \n",
    "3. Blue box: Lineare Transformation auf dem Output\n",
    "4. Red box: Wahrscheinlichkeiten\n",
    "5. Purple box: Loss berechnen mit Cross Entropy Funktion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function  # LINEAR\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellklasse instanzieren\n",
    "\n",
    "- Input dimension: 784\n",
    "    * Size of image\n",
    "        * 28×28=784\n",
    "- Output dimension: 10 (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)    \n",
    "\n",
    "- Hidden dimension: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "- Feedforward Neural Network: **Cross Entropy Loss**\n",
    "    - Berechnung des Fehlers zwishen den softmax output und den Labels\n",
    "    \n",
    "\n",
    "Achtung: \n",
    "- Die `CrossEntropyLoss`-Funktion in PyTorch berechnet automatisch die Softmax-Werte. Deswegen muss man beim letzten Schritt im Forward-Pass kein Softmax berechnen    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "- Stochastich Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter von einem Netz untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# FC 2 Parameters\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# FC 2 Bias Parameters\n",
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell trainieren\n",
    "\n",
    "1. Input zu Tensoren umwandeln mit requires_grad \n",
    "2. Gradient-Buffer zurücksetzen: `zero_grad()`\n",
    "3. Berechnung des Outputs \n",
    "4. Berechnung des Fehlers durch Anwendung des `criterion` auf die berechneten Ergebnisse und bestehenden Labels\n",
    "5. Berechnung der Gradienten bezüglich der Parameter: `backward()`\n",
    "6. Parameter über den Optimizer aktualisieren: `step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.6097607612609863. Accuracy: 86.43%\n",
      "Iteration: 1000. Loss: 0.4247399866580963. Accuracy: 89.50%\n",
      "Iteration: 1500. Loss: 0.4123305380344391. Accuracy: 90.46%\n",
      "Iteration: 2000. Loss: 0.2970556616783142. Accuracy: 91.15%\n",
      "Iteration: 2500. Loss: 0.2933889627456665. Accuracy: 91.71%\n",
      "Iteration: 3000. Loss: 0.2421608418226242. Accuracy: 92.07%\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step() #parameters = parameters - learning_rate * parameters_gradients\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "    \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0) #100\n",
    "\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell B: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.24110135436058044. Accuracy: 91.33%\n",
      "Iteration: 1000. Loss: 0.2077825516462326. Accuracy: 93.12%\n",
      "Iteration: 1500. Loss: 0.2603013515472412. Accuracy: 94.23%\n",
      "Iteration: 2000. Loss: 0.3106187582015991. Accuracy: 94.78%\n",
      "Iteration: 2500. Loss: 0.21734096109867096. Accuracy: 95.46%\n",
      "Iteration: 3000. Loss: 0.13929630815982819. Accuracy: 95.72%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity\n",
    "        out = self.relu(out)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0) #jedes Mal um 100 erhöht\n",
    "                \n",
    "                ######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model C: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)\n",
    "\n",
    "<img src=\"nn2.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.5177395939826965. Accuracy: 91.50%\n",
      "Iteration: 1000. Loss: 0.2385992854833603. Accuracy: 93.31%\n",
      "Iteration: 1500. Loss: 0.07126786559820175. Accuracy: 94.82%\n",
      "Iteration: 2000. Loss: 0.1462179273366928. Accuracy: 95.75%\n",
      "Iteration: 2500. Loss: 0.07994501292705536. Accuracy: 96.04%\n",
      "Iteration: 3000. Loss: 0.10123749822378159. Accuracy: 96.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3 (readout): 100 --> 10\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 3 (readout)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Convolutional Neural Network (CNN)\n",
    "\n",
    "Basic CNN - 2 zusätzliche Layer vor dem Feedforward Network:\n",
    "- Convolution Layer\n",
    "- Pooling Layer \n",
    "\n",
    "<img src=\"cnn1.png\" >\n",
    "\n",
    "Quelle: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell A: \n",
    "- 2 Convolutional Layers\n",
    "    - Same Padding (same output size)\n",
    "- 2 Max Pooling Layers\n",
    "- 1 Fully Connected Layer\n",
    "\n",
    "\n",
    "**FORMELN:**\n",
    "\n",
    "**OUTPUT FORMEL FÜR CONVOLUTION**:\n",
    "\n",
    "- $O = \\frac {W - K + 2P}{S} + 1$\n",
    "    - O: output height/length\n",
    "    - W: input height/length\n",
    "    - K: filter size (kernel size) = 5\n",
    "    - P:  same padding (non-zero)\n",
    "        * $P = \\frac{K - 1}{2}  = \\frac{5 - 1}{2} = 2$\n",
    "    - S: stride = 1\n",
    "\n",
    "**OUTPUT FORMEL FÜR POOLING**:\n",
    "- $O = \\frac {W - K}{S} + 1$\n",
    "    - W: input height/width\n",
    "    - K: filter size = 2\n",
    "    - S: stride size = filter size, PyTorch defaults the stride to kernel filter size\n",
    "        - Es wird das default PyTorch stride, also gilt diese Formel $O = \\frac {W}{K}$\n",
    "    \n",
    "<img src=\"cnn10-2n.png\">\n",
    "\n",
    "Quelle: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# Convolution 1: 16 Kernels\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Convolution 1 Bias: 16 Kernels\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Convolution 2: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Convolution 2 Bias: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Fully Connected Layer Bias\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Umwandlung der Inputs nach Tensoren mit requires_grad aktiv\n",
    "    - CNN Input: (1,28,28)\n",
    "    - Feedforward Input: (1, 28*28)\n",
    "2. Gradient-Buffer zurücksetzen: `zero_grad()`\n",
    "3. Berechnung des Outputs \n",
    "4. Berechnung des Fehlers durch Anwendung des `criterion` auf die berechneten Ergebnisse und bestehenden Labels\n",
    "5. Berechnung der Gradienten bezüglich der Parameter: `backward()`\n",
    "6. Parameter über den Optimizer aktualisieren: `step()`         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images\n",
    "        images = images.requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images\n",
    "                images = images.requires_grad_().to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "\n",
    "            accuracy = 100. * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {:.2f}%'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen\n",
    "\n",
    "Udacity:\n",
    "    - Deep Learning with PyTorch(Tutorial): \n",
    "    - Deep Learning with PyTorch (Repo): https://github.com/udacity/deep-learning-v2-pytorch\n",
    "\n",
    "Deep Learning Wizard, \"Practical PyTorch\": https://www.deeplearningwizard.com/deep_learning/practical_pytorch\n",
    "\n",
    "Siraj Raval, \"Pytorch in 5 Minutes\": https://www.youtube.com/watch?v=nbJ-2G2GXL0 (very quick start)\n",
    "\n",
    "IAML (Italian Association for Machine Learning), \"Fun with PyTorch\": https://iaml.it/blog/fun-with-pytorch-part-1\n",
    "\n",
    "PyTorch, Neural Networks - PyTorch Tutorials: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "PyTorch Documentation: https://pytorch.org/docs/stable/index.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
