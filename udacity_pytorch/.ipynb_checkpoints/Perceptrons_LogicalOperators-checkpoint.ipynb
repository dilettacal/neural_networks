{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"index--markdown--3w8oF ureact-markdown \"><h2 id=\"what-are-the-weights-and-bias-for-the-and-perceptron-\">What are the weights and bias for the AND perceptron?</h2>\n",
    "<p>Set the weights (<code>weight1</code>, <code>weight2</code>)  and bias (<code>bias</code>) to values that will correctly determine the AND operation as shown above.<br>More than one set of values will work!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear combi:  -1.0\n",
      "input:  (0, 0)\n",
      "output:  0\n",
      "Linear combi:  -0.5\n",
      "input:  (0, 1)\n",
      "output:  0\n",
      "Linear combi:  -0.5\n",
      "input:  (1, 0)\n",
      "output:  0\n",
      "Linear combi:  0.0\n",
      "input:  (1, 1)\n",
      "output:  1\n",
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                  -1.0                    0          Yes\n",
      "      0          1                  -0.5                    0          Yes\n",
      "      1          0                  -0.5                    0          Yes\n",
      "      1          1                   0.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.5\n",
    "weight2 = 0.5\n",
    "bias = -1\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    print(\"Linear combi: \", linear_combination)\n",
    "    print(\"input: \", test_input)\n",
    "    print(\"output: \", output)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Perceptrons\n",
    "\n",
    "The OR perceptron is very similar to an AND perceptron. In the image below, the OR perceptron has the same line as the AND perceptron, except the line is shifted down. What can you do to the weights and/or bias to achieve this? Use the following AND perceptron to create an OR Perceptron.\n",
    "\n",
    "What are two ways to go from an AND perceptron to an OR perceptron?\n",
    "- Increase the weights\n",
    "- Decrease the magnitude of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear combi:  -0.5\n",
      "input:  (0, 0)\n",
      "output:  0\n",
      "Linear combi:  0.5\n",
      "input:  (0, 1)\n",
      "output:  1\n",
      "Linear combi:  0.5\n",
      "input:  (1, 0)\n",
      "output:  1\n",
      "Linear combi:  1.5\n",
      "input:  (1, 1)\n",
      "output:  1\n",
      "Nice!  You got it all correct.\n",
      "\n",
      "Results:\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                  -0.5                    0          Yes\n",
      "      0          1                   0.5                    1          Yes\n",
      "      1          0                   0.5                    1          Yes\n",
      "      1          1                   1.5                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1\n",
    "weight2 = 1\n",
    "bias = -0.5\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    print(\"Linear combi: \", linear_combination)\n",
    "    print(\"input: \", test_input)\n",
    "    print(\"output: \", output)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(\"Results:\")    \n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"not-perceptron\">NOT Perceptron</h1>\n",
    "<p>Unlike the other perceptrons we looked at, the NOT operation only cares about one input.  The operation returns a <code>0</code> if the input is <code>1</code> and a <code>1</code> if it's a <code>0</code>.  The other inputs to the perceptron are ignored.</p>\n",
    "<p>In this quiz, you'll set the weights (<code>weight1</code>, <code>weight2</code>)  and bias <code>bias</code> to the values that calculate the NOT operation on the second input and ignores the first input.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                   0.0                    1          Yes\n",
      "      0          1                  -0.5                    0          Yes\n",
      "      1          0                   0.0                    1          Yes\n",
      "      1          1                  -0.5                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0\n",
    "weight2 = -0.5\n",
    "bias = 0\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the equation of a decision boundary and input data (e.g. in the form of a point), how can we move the line toward the point?\n",
    "\n",
    "1. Equation: w1x1 + w2x2 + b = 0\n",
    "2. Positive class: w1x1 + w2x2 + b > 0\n",
    "3. Negative classe: w1x1 + w2x2 + b < 0\n",
    "\n",
    "Examples:\n",
    "1. Equation = 3x1 +4x2 -10 = 0\n",
    "2. Positive misclassified Point = (4,5)\n",
    "3. Negative misclassified Point = (1,1)\n",
    "\n",
    "**First case: Point is misclassified as positive** (Subtraction)\n",
    "<br> 3   4   -10 [Line parameter]\n",
    "<br>-            \n",
    "<br> 4   5   1   [Point parameter, 1 is supposed to be the point bias]\n",
    "<br> ---------\n",
    "<br> -1  -1  -11\n",
    "\n",
    "Thus the new line hast the equation: -1x1 -1x2 -11 \n",
    "\n",
    "**Second case: Point is misclassified as negatie** (Addition)\n",
    "\n",
    "<br> 3   4   -10 [Line parameter]\n",
    "<br>+            \n",
    "<br> 1   1   1   [Point parameter, 1 is supposed to be the point bias]\n",
    "<br> ---------\n",
    "<br> 4   5  9\n",
    "\n",
    "Thus the new line has the equation: 4x1 + 5x2 + 9\n",
    "\n",
    "\n",
    "**Learning rate**\n",
    "Suppose we do not want to move the line so drastically, but we want to reduce the pace. In that case we define a learning rate $\\alpha = 0.1$  which is multiplied to the point parameters: \n",
    "\n",
    "1. 3-(0.1\\*4) | 4-(0.1\\*5) | (-10 -(0.1\\*1) = 3-0.4 | 4-0.5 |(-10-0.1) --> 2.6x1 +3.5x2 -10.1\n",
    "\n",
    "2. 3+0.1 | 4+0.1 | -10+0.1 --> 3.1x1 + 4.1x2 -9.9\n",
    "\n",
    "For this second example, if the learning rate is set to 0.1, then we need to perform the change 10 times, in order to move the line to a position closer to the misclassified point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "1. Initialize the weigths with random values: weights w1,w2, ..., wn\n",
    "2. For every misclassified point(x1,...,xn):\n",
    "    2.1 if **prediction=0**:\n",
    "        - For i = 1,...,n\n",
    "            - Change w_i + alpha*x_i\n",
    "        - Change b to b+alpha\n",
    "    2.2 if **prediction=1**:\n",
    "        - For i = 1..n\n",
    "            - Change w_i - alpha*x_i\n",
    "            - Change b to b - alpha\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the perceptron step works as follows. For a point with coordinates\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>p</mi><mo separator=\"true\">,</mo><mi>q</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(p,q)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">p</span><span class=\"mpunct\">,</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">q</span><span class=\"mclose\">)</span></span></span></span>, label <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\"> y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span>, and prediction given by the equation <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>y</mi></mrow><mo>^</mo></mover><mo>=</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mo>(</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi>b</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{y} = step(w_1x_1 + w_2x_2 + b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\">s</span><span class=\"mord mathit\">t</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">b</span><span class=\"mclose\">)</span></span></span></span>:</p>\n",
    "<ul>\n",
    "<li>If the point is correctly classified, do nothing.</li>\n",
    "<li>If the point is classified positive, but it has a negative label, subtract\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi><mi>p</mi><mo separator=\"true\">,</mo><mi>α</mi><mi>q</mi><mo separator=\"true\">,</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha p, \\alpha q,</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathit\">p</span><span class=\"mpunct\">,</span><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span></span></span></span> and\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span></span></span></span>\n",
    "from\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo></mrow><annotation encoding=\"application/x-tex\">w_1, w_2,</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span></span></span></span>\n",
    "and\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">b</span></span></span></span>\n",
    "respectively.</li>\n",
    "<li>If the point is classified negative, but it has a positive label, add\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi><mi>p</mi><mo separator=\"true\">,</mo><mi>α</mi><mi>q</mi><mo separator=\"true\">,</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha p, \\alpha q,</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathit\">p</span><span class=\"mpunct\">,</span><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span></span></span></span>\n",
    "and\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.0037em;\">α</span></span></span></span>\n",
    "to\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator=\"true\">,</mo></mrow><annotation encoding=\"application/x-tex\">w_1, w_2,</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span></span></span></span>\n",
    "and\n",
    "<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">b</span></span></span></span>\n",
    "respectively.</li>\n",
    "</ul>\n",
    "<p>Then click on <code>test run</code> to graph the solution that the perceptron algorithm gives you. It'll actually draw a set of dotted lines, that show how the algorithm approaches to the best solution, given by the black solid line.</p>\n",
    "<p>Feel free to play with the parameters of the algorithm (number of epochs, learning rate, and even the randomizing of the initial parameters) to see how your initial conditions can affect the solution!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i], W, b)\n",
    "        if y[i] - y_hat == 1:\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "        elif y[i] - y_hat == -1:  \n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])bab\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
