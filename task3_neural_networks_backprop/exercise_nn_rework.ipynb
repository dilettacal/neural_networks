{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Fundamentals - Neural Networks - Exercise: Minimal Fully Connected Network for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Requirements](#Requirements) \n",
    "  * [Modules](#Python-Modules) \n",
    "  * [Data](#Data)\n",
    "* [Simple MNIST Network](#Simple-MNIST-Network)\n",
    "  * [Todo: Transparency](#Todo:-Transparency)\n",
    "  * [Todo: Comprehension](#Todo:-Comprehension)\n",
    "  * [Todo: Step towards a NN-Framework](#Todo:-Step-towards-a-NN-Framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# internal\n",
    "from deep_teaching_commons.data.fundamentals.mnist import Mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto download is active, attempting download\n",
      "mnist data directory already exists, download aborted\n"
     ]
    }
   ],
   "source": [
    "# create mnist loader from deep_teaching_commons\n",
    "mnist_loader = Mnist(data_dir='data')\n",
    "\n",
    "# load all data, labels are one-hot-encoded, images are flatten and pixel squashed between [0,1]\n",
    "train_images, train_labels, test_images, test_labels = mnist_loader.get_all_data(one_hot_enc=True, normalized=True)\n",
    "\n",
    "# shuffle training data\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "train_images, train_labels = train_images[shuffle_index], train_labels[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MNIST Network\n",
    "The presented network is an adaptation of Michael Nielson's introductory example to neural networks. It is recommended, though not necessary, to read the first two chapters of his great online book ['Neural Networks and Deep Learning'](http://neuralnetworksanddeeplearning.com/) for a better understanding of the given example. Compared to the [original](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py) by Nielsen, the present variant was vectorized and the sigmoid activation function replaced by a rectified linear unit function (ReLU). As a result, the code is written much more compact, and the optimization of the model is much more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo: Transparency\n",
    "Your goal is to understand how the implementation works. Therefore you can do the following:\n",
    "  - Add comments to functions and lines of code. Follow the [Google-Pyhton](https://google.github.io/styleguide/pyguide.html) guidelines for comments.\n",
    "  - Add a verbose argument (`boolean`) to the functions that adds meaningful `print` lines to the network, if it is `true`.\n",
    "  - Add a variable `delta_hist` which store the delta value calculated on the output layer during each iteration of the function `grads(X,Y,weights)`. After the optimization process plot `delta_hist`.\n",
    "  \n",
    "Hopefully, this implementation of a neural network is clear after your investigation. You should be able to answer following questions:\n",
    "  - Which cost function is used, what is its derivation and how is it implemented?\n",
    "      - The network uses softmax as loss function\n",
    "  - Why are the boundaries of your plot between [-1,0], why it is so noisy, how do you can reduce the noice and what is the difference to a usual plot of a loss function?\n",
    "      - There is noise because of the batch gradient descent. To reduce the noice you need to choose a bigger batch size. [-1,0] because the loss is always positive?\n",
    "  - How does the network implement the backpropagation algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_hist =[]\n",
    "\n",
    "def feed_forward(X, weights):\n",
    "    \"\"\"Preforms the forward pass.\n",
    "    \n",
    "        Args:\n",
    "            X: A batch of inputs\n",
    "            weights: The weights\n",
    "            \n",
    "        Returns:\n",
    "            A batch of calculated outputs\n",
    "        \n",
    "    \"\"\"\n",
    "    a = [X]\n",
    "    for w in weights:\n",
    "        a.append(np.maximum(a[-1].dot(w),0))\n",
    "    return a\n",
    "\n",
    "def grads(X, Y, weights):\n",
    "    \"\"\"Calculates the gradients and preforms the backpropagation\n",
    "    \n",
    "        Args:\n",
    "            X: inputs\n",
    "            Y: labels\n",
    "            weights: weights to calculate the new gradient\n",
    "        \n",
    "        Returns:\n",
    "            The new gradients\n",
    "\n",
    "    \"\"\"\n",
    "    grads = np.empty_like(weights)\n",
    "    a = feed_forward(X, weights)\n",
    "    # https://brilliant.org/wiki/backpropagation/ or https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications\n",
    "    delta = a[-1] - Y\n",
    "    \n",
    "    delta_hist.append(np.sum(delta*Y)/len(X))\n",
    "    grads[-1] = a[-2].T.dot(delta)\n",
    "    for i in range(len(a)-2, 0, -1):\n",
    "        delta = (a[i] > 0) * delta.dot(weights[i].T)\n",
    "        grads[i-1] = a[i-1].T.dot(delta)\n",
    "    return grads / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n",
      "J:  59950\n",
      "(50, 784)\n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "trX, trY, teX, teY = train_images, train_labels, test_images, test_labels\n",
    "#Start bei 200 Knoten, jeweils mit 784 Zeilen\n",
    "#1. HL: 100 Knoten, jeweils mit 200 Zeilen\n",
    "#Output layers: 10 Klassen, jeweils mit 100 Zeilen\n",
    "layers = [(784, 200), (200,100), (100, 10)]\n",
    "#Create weights for every layers: They have the same shape as in layers\n",
    "weights = [np.random.randn(*w) * 0.1 for w in layers]\n",
    "\n",
    "#Define Epochs for each gradient batch\n",
    "#Data divided in groups of 50 examples, each is trained 20 times with an alpha of 0.1\n",
    "num_epochs, batch_size, learn_rate = 20, 50, 0.1\n",
    "\n",
    "#Add a verbose argument (boolean) to the functions that adds meaningful print lines to the network, if it is true.\n",
    "#Add verbose\n",
    "verbose = False\n",
    "for i in range(num_epochs):\n",
    "    #Loop through data with a step of batch_size\n",
    "    #60000, 50\n",
    "    for j in range(0, len(trX), batch_size):\n",
    "        X, Y = trX[j:j+batch_size], trY[j:j+batch_size]\n",
    "        weights -= learn_rate * grads(X, Y, weights)\n",
    "        once = False\n",
    "    prediction_test = np.argmax(feed_forward(teX, weights)[-1], axis=1)\n",
    "    print(\"J: \", j)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    if verbose:\n",
    "        print(\"Epoch:\", i, \"Accuracy:\", np.mean(prediction_test == np.argmax(teY, axis=1)), \"Delta:\", delta_hist[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50, 0.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs, batch_size, learn_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22e1671f470>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(delta_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo: Step towards a NN-Framework\n",
    "The presented implementation is compact and efficient, but hard to modify or extend. However, a modular design is crucial if you want to experiment with a neural network to understand the influence of its components. Now you make the first changes towards your own 'toy-neural-network-framework', which you should expand in the progress of the course. \n",
    "\n",
    "Rework the implementation from above given the classes and methods below. Again, you _do not_ have to re-engineer the whole neural network at this step. Rework the code to match the given specification and do necessary modifications only. For your understanding, you can change the names of the variables to more fitting ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "This is your duty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-950fd92f029d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmnist_NN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullyConnectedNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_NN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_NN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_hist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-950fd92f029d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, network, train_data, train_labels, test_data, test_labels, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is your duty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: This is your duty"
     ]
    }
   ],
   "source": [
    "class FullyConnectedNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = [np.random.randn(*w) * 0.1 for w in self.layers]\n",
    "        self.delta_hist = []\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        a = [data]\n",
    "        for w in self.weights:\n",
    "            a.append(np.maximum(a[-1].dot(w),0))\n",
    "        return a\n",
    "\n",
    "    def backward(self, X, Y):\n",
    "        return None\n",
    "\n",
    "    def predict(self, data):\n",
    "        return None\n",
    "            \n",
    "class Optimizer:\n",
    "    def __init__(self, network, train_data, train_labels, test_data=None, test_labels=None, epochs=100, batch_size=20, learning_rate=0.01):\n",
    "        raise NotImplementedError(\"This is your duty\")\n",
    "        \n",
    "    def sgd(self):\n",
    "        return None\n",
    "\n",
    "    \n",
    "# Following code should run:    \n",
    "mnist_NN = FullyConnectedNetwork([(784, 200),(200,100),(100, 10)]) \n",
    "epochs, batch_size, learning_rate = 20, 500, 0.1\n",
    "Optimizer(mnist_NN, train_images, train_labels, test_images, test_labels, epochs, batch_size, learning_rate)\n",
    "plt.plot(mnist_NN.delta_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
